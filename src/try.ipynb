{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f726ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if we can import vit-prisma\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from vit_prisma.utils.constants import (\n",
    "    DEVICE,\n",
    ")\n",
    "from vit_prisma.utils.tutorial_utils import (\n",
    "    get_feature_activations,\n",
    "    plot_act_distribution,\n",
    "    plot_image,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165d5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    _project_root = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    _project_root = Path.cwd().parent\n",
    "\n",
    "if str(_project_root) not in sys.path:\n",
    "    sys.path.append(str(_project_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4cf3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/nfs/turbo/coe-chaijy/janeding/regrounding/results_log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c344342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# clear cache\n",
    "torch.cuda.empty_cache()\n",
    "# force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "DEVICE = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4e7703",
   "metadata": {},
   "source": [
    "# Step 1: Load Transcoder and CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3880bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 00:57:45 DEBUG:urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 00:57:45 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /Prisma-Multimodal/CLIP-transcoder-topk-768-x64-all_patches_0-mlp-96/resolve/main/weights.pt HTTP/1.1\" 302 0\n",
      "2025-07-24 00:57:45 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /Prisma-Multimodal/CLIP-transcoder-topk-768-x64-all_patches_0-mlp-96/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "2025-07-24 00:57:45 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Prisma-Multimodal/CLIP-transcoder-topk-768-x64-all_patches_0-mlp-96/b9ff9647261516e5c7a882f7fd130db702c8ea25/config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE from /nfs/turbo/coe-chaijy-unreplicated/pre-trained-weights/prisma-sae/models--Prisma-Multimodal--CLIP-transcoder-topk-768-x64-all_patches_0-mlp-96/snapshots/b9ff9647261516e5c7a882f7fd130db702c8ea25/weights.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 00:57:47 INFO:root: get_activation_fn received: activation_fn=topk, kwargs={'k': 768}\n",
      "2025-07-24 00:57:47 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /Prisma-Multimodal/CLIP-transcoder-topk-256-x64-all_patches_1-mlp-94/resolve/main/weights.pt HTTP/1.1\" 302 0\n",
      "2025-07-24 00:57:47 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /Prisma-Multimodal/CLIP-transcoder-topk-256-x64-all_patches_1-mlp-94/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "2025-07-24 00:57:47 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Prisma-Multimodal/CLIP-transcoder-topk-256-x64-all_patches_1-mlp-94/96c293a7299a99fe3d70f1f15498215849f22d96/config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE from /nfs/turbo/coe-chaijy-unreplicated/pre-trained-weights/prisma-sae/models--Prisma-Multimodal--CLIP-transcoder-topk-256-x64-all_patches_1-mlp-94/snapshots/96c293a7299a99fe3d70f1f15498215849f22d96/weights.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 00:57:48 INFO:root: get_activation_fn received: activation_fn=topk, kwargs={'k': 256}\n",
      "2025-07-24 00:57:48 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /Prisma-Multimodal/CLIP-transcoder-topk-1024-x64-all_patches_2-mlp-93/resolve/main/weights.pt HTTP/1.1\" 302 0\n"
     ]
    }
   ],
   "source": [
    "# Load all transcoders\n",
    "from src.analysis.utils import *\n",
    "\n",
    "tc_list = load_all_tc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf9ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionModelSAERunnerConfig(model_class_name='HookedViT',\n",
      "                           model_name='open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K',\n",
      "                           vit_model_cfg=None,\n",
      "                           model_path=None,\n",
      "                           hook_point_layer=10,\n",
      "                           layer_subtype='ln2.hook_normalized',\n",
      "                           hook_point_head_index=None,\n",
      "                           context_size=50,\n",
      "                           use_cached_activations=False,\n",
      "                           use_patches_only=False,\n",
      "                           cached_activations_path='activations/_network_scratch_s_sonia.joseph_datasets_kaggle_datasets/open-clip:laion_CLIP-ViT-B-32-DataComp.XL-s13B-b90K/blocks.9.ln2.hook_normalized',\n",
      "                           image_size=224,\n",
      "                           architecture='standard',\n",
      "                           b_dec_init_method='geometric_median',\n",
      "                           expansion_factor=64,\n",
      "                           from_pretrained_path=None,\n",
      "                           is_transcoder=True,\n",
      "                           transcoder_with_skip_connection=True,\n",
      "                           out_hook_point_layer=10,\n",
      "                           layer_out_subtype='hook_mlp_out',\n",
      "                           d_out=768,\n",
      "                           _device='cuda',\n",
      "                           seed=42,\n",
      "                           _dtype='float32',\n",
      "                           d_in=768,\n",
      "                           activation_fn_str='topk',\n",
      "                           activation_fn_kwargs={'k': 1024},\n",
      "                           cls_token_only=False,\n",
      "                           max_grad_norm=1.0,\n",
      "                           initialization_method='independent',\n",
      "                           normalize_activations='layer_norm',\n",
      "                           n_batches_in_buffer=20,\n",
      "                           store_batch_size=32,\n",
      "                           num_workers=16,\n",
      "                           num_epochs=1,\n",
      "                           verbose=False,\n",
      "                           l1_coefficient=0.0002,\n",
      "                           lp_norm=1,\n",
      "                           lr=0.0010281538518292835,\n",
      "                           lr_scheduler_name='cosineannealingwarmup',\n",
      "                           lr_warm_up_steps=500,\n",
      "                           train_batch_size=4096,\n",
      "                           dataset_name='imagenet1k',\n",
      "                           dataset_path='/network/scratch/s/sonia.joseph/datasets/kaggle_datasets',\n",
      "                           dataset_train_path='/network/scratch/s/sonia.joseph/datasets/kaggle_datasets/ILSVRC/Data/CLS-LOC/train',\n",
      "                           dataset_val_path='/network/scratch/s/sonia.joseph/datasets/kaggle_datasets/ILSVRC/Data/CLS-LOC/val',\n",
      "                           use_ghost_grads=False,\n",
      "                           feature_sampling_window=1000,\n",
      "                           dead_feature_window=5000,\n",
      "                           dead_feature_threshold=1e-08,\n",
      "                           log_to_wandb=True,\n",
      "                           wandb_project='openclip-transcoders',\n",
      "                           wandb_entity=None,\n",
      "                           wandb_log_frequency=10,\n",
      "                           n_validation_runs=0,\n",
      "                           n_checkpoints=10,\n",
      "                           checkpoint_path='/network/scratch/p/praneet.suresh/openclip-transcoder-checkpoints/4941547c-openclip-transcoders')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'blocks.10.ln2.hook_normalized'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will first start by the last transcoder\n",
    "from pprint import pprint\n",
    "\n",
    "tc_10 = tc_list[10]\n",
    "pprint(tc_10.cfg)\n",
    "tc_10.cfg.hook_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open_clip.tokenizer.SimpleTokenizer object at 0x7f32bedca780>\n"
     ]
    }
   ],
   "source": [
    "# DEVICE = 'cuda:0'\n",
    "\n",
    "\n",
    "# load text model\n",
    "def name_from_hf(model_name):\n",
    "    \"\"\"return model name from huggingface\"\"\"\n",
    "    return model_name.replace(\"open-clip:\", \"hf-hub:\")\n",
    "\n",
    "\n",
    "import open_clip\n",
    "\n",
    "# model_name = name_from_hf(tc_10.cfg.model_name)\n",
    "# print(model_name)\n",
    "model_name = \"hf-hub:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(\n",
    "    model_name\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "print(tokenizer)\n",
    "\n",
    "print(preprocess_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e531818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedViT(\n",
       "  (embed): PatchEmbedding(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
       "  )\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbedding()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (hook_full_embed): HookPoint()\n",
       "  (ln_pre): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (hook_ln_pre): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (hook_ln_final): HookPoint()\n",
       "  (head): Head()\n",
       "  (hook_post_head_pre_normalize): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load vision model\n",
    "from vit_prisma.models.model_loader import load_hooked_model\n",
    "from vit_prisma.utils.enums import ModelType\n",
    "\n",
    "model_name = tc_10.cfg.model_name\n",
    "print(model_name)\n",
    "\n",
    "model_v = load_hooked_model(model_name, model_type=ModelType.VISION)\n",
    "model_v.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11141327",
   "metadata": {},
   "source": [
    "# Step 2: Load image and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca4c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING\tTask(Task-2) matplotlib.image:image.py:_normalize_image_array()- Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7922626..2.145897].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load image\n",
    "from PIL import Image\n",
    "from vit_prisma.transforms import get_clip_val_transforms\n",
    "\n",
    "# img_path = '/nfs/turbo/coe-chaijy/janeding/example_images/smiling-face.png'\n",
    "img_path = (\n",
    "    \"/nfs/turbo/coe-chaijy/janeding/regrounding/example_images/biochemist.png\"\n",
    ")\n",
    "gt_label = \"chemist\"\n",
    "img = Image.open(img_path).convert()  # Ensure it's 3 channels\n",
    "transforms = get_clip_val_transforms()\n",
    "img_tensor = transforms(img)\n",
    "plot_image(img_tensor.detach().cpu(), unstandardise=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26986511",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "img_2 = Image.open('/nfs/turbo/coe-chaijy/janeding/example_images/chemistry.png').convert()\n",
    "transforms = get_clip_val_transforms()\n",
    "img_tensor = transforms(img_2)\n",
    "plot_image(img_tensor.detach().cpu(), unstandardise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479786ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded from: concreteness_rating.csv\n",
      "Total 39957 labels\n",
      "\n",
      "first 10 labels:\n",
      "0: partisan\n",
      "1: homebound\n",
      "2: bogged down\n",
      "3: pillager\n",
      "4: vivaciousness\n",
      "5: pornographically\n",
      "6: burrower\n",
      "7: reelect\n",
      "8: involuntarily\n",
      "9: bald\n",
      "\n",
      "last 10 labels:\n",
      "39947: jogger\n",
      "39948: couch\n",
      "39949: becoming\n",
      "39950: dateline\n",
      "39951: echogram\n",
      "39952: codeine\n",
      "39953: nauseate\n",
      "39954: shorter\n",
      "39955: setoff\n",
      "39956: oceanic\n",
      "\n",
      "Labels are ready, can be used for model input\n",
      "for example: labels[0] = 'partisan'\n"
     ]
    }
   ],
   "source": [
    "# see how clip will classify the image\n",
    "\n",
    "# load labels\n",
    "import ast\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# load imagenet 1000 labels\n",
    "def load_labels_txt(file_path=\"imagenet-1000.txt\") -> List:\n",
    "    \"\"\"\n",
    "    load imagenet 1000 labels and return a list of labels\n",
    "    \"\"\"\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # parse dict\n",
    "    labels_dict = ast.literal_eval(content)\n",
    "\n",
    "    # convert to list, sorted by index\n",
    "    labels_list = [labels_dict[i] for i in range(len(labels_dict))]\n",
    "\n",
    "    return labels_list\n",
    "\n",
    "\n",
    "def load_words_from_txt(file_path):\n",
    "    \"\"\"return a list of words from a txt file\"\"\"\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        words = [line.strip() for line in f]\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "def load_labels_csv(file_path=\"concreteness_rating.csv\") -> List:\n",
    "    \"\"\"\n",
    "    load concreteness rating labels and return a list of labels\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    labels = df[\"Word\"].tolist()\n",
    "    labels = [\n",
    "        str(label) for label in labels if pd.notna(label) and str(label).strip()\n",
    "    ]\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_labels(file_path=\"concreteness_rating.csv\", num_labels=-1) -> List:\n",
    "    import random\n",
    "\n",
    "    from src.extra_labels import EXTRA_LABELS\n",
    "\n",
    "    if \"20k\" in file_path:\n",
    "        labels = load_words_from_txt(file_path)\n",
    "    elif file_path.endswith(\".txt\"):\n",
    "        labels = load_labels_txt(file_path)\n",
    "    elif file_path.endswith(\".csv\"):\n",
    "        labels = load_labels_csv(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_path}\")\n",
    "\n",
    "    if num_labels > 0:\n",
    "        labels = random.sample(labels, num_labels)\n",
    "    # add extra labels\n",
    "    labels.extend(EXTRA_LABELS)\n",
    "    labels = list(set(labels))\n",
    "    return labels\n",
    "\n",
    "\n",
    "# load labels\n",
    "file_path = \"concreteness_rating.csv\"\n",
    "labels = load_labels(file_path=file_path)\n",
    "\n",
    "# show first 10 labels\n",
    "print(f\"Labels loaded from: {file_path}\")\n",
    "print(f\"Total {len(labels)} labels\")\n",
    "print(\"\\nfirst 10 labels:\")\n",
    "for i, label in enumerate(labels[: min(10, len(labels))]):\n",
    "    print(f\"{i}: {label}\")\n",
    "\n",
    "print(\"\\nlast 10 labels:\")\n",
    "for i, label in enumerate(\n",
    "    labels[-min(10, len(labels)) :], len(labels) - min(10, len(labels))\n",
    "):\n",
    "    print(f\"{i}: {label}\")\n",
    "\n",
    "# can also use list directly\n",
    "print(\"\\nLabels are ready, can be used for model input\")\n",
    "print(f\"for example: labels[0] = '{labels[0]}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b985f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear cache\n",
    "torch.cuda.empty_cache()\n",
    "# force garbage collection\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1854d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. label: scientist            | prob: 0.2507\n",
      "2. label: chemist              | prob: 0.1971\n",
      "3. label: biochemist           | prob: 0.0807\n",
      "4. label: toxicologist         | prob: 0.0429\n",
      "5. label: experimentalist      | prob: 0.0401\n",
      "6. label: nonscientist         | prob: 0.0309\n",
      "7. label: pharmacologist       | prob: 0.0300\n",
      "8. label: sexologist           | prob: 0.0182\n",
      "9. label: cosmologist          | prob: 0.0166\n",
      "10. label: geochemist           | prob: 0.0148\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 512\n",
    "\n",
    "\n",
    "prompts = [f\"a photo of a {l}\" for l in labels]\n",
    "text_tokens = open_clip.tokenize(prompts)  # [N, 77] on CPU\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_input = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "    image_features = model.encode_image(image_input)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_feats_out = []\n",
    "    for i in range(0, len(text_tokens), CHUNK_SIZE):\n",
    "        chunk = text_tokens[i : i + CHUNK_SIZE].to(DEVICE, non_blocking=True)\n",
    "        feats = model.encode_text(chunk)\n",
    "        feats = feats / feats.norm(dim=-1, keepdim=True)\n",
    "        text_feats_out.append(feats.cpu())\n",
    "    text_features = torch.cat(text_feats_out).to(DEVICE)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    top_probs, top_idx = text_probs.squeeze().topk(10)\n",
    "\n",
    "for i, (prob, idx) in enumerate(zip(top_probs, top_idx)):\n",
    "    print(f\"{i+1}. label: {labels[idx]:<20} | prob: {prob.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59778bbc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "with torch.no_grad():\n",
    "    # prepare image and text input\n",
    "    image_input = img_tensor.unsqueeze(0).to(DEVICE) # add batch dimension\n",
    "    # add the template for a better matching\n",
    "    text_inputs = torch.cat([tokenizer(f'a photo of a {label}') for label in labels]).to(DEVICE)\n",
    "\n",
    "    # encode image and text\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    \n",
    "    # normalize features\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # calculate similarity and convert to probability\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "    # get top 10 most likely labels\n",
    "    top_probs, top_indices = torch.topk(text_probs.squeeze(), 10)\n",
    "\n",
    "for i, (prob, idx) in enumerate(zip(top_probs, top_indices)):\n",
    "    print(f\"{i+1}. label: {labels[idx]:<20} | prob: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f275f",
   "metadata": {},
   "source": [
    "# Step 3: Find $f_{end}$\n",
    "We will calculate the cos similarity for the label \"chemistry\"'s text embedding and the transcoder decoder matrix of the last layer, to get the most related feature, also our destination $f_{end}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cccfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get text embedding\n",
    "# gt_label = 'chemistry'\n",
    "# gt_label = 'smile'\n",
    "text_input = tokenizer([gt_label]).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    text_embedding = model.encode_text(text_input)\n",
    "    text_embedding = text_embedding / text_embedding.norm(dim=-1, keepdim=True)\n",
    "\n",
    "text_embedding.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 49152])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_vectors = tc_10.W_dec.T\n",
    "decoder_vectors = decoder_vectors / decoder_vectors.norm(dim=-1, keepdim=True)\n",
    "decoder_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26905c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 49152])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_decoder_vectors = model.visual.proj.T @ decoder_vectors\n",
    "projected_decoder_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60badf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8606e-04, -1.5921e-03, -6.1627e-04,  ...,  8.6095e-05,\n",
       "          1.4082e-03,  2.7063e-03]], device='cuda:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = text_embedding @ projected_decoder_vectors\n",
    "similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681fef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in MLP layer, the most related visual feature (f_end) index is: 46014\n",
      "cosine similarity in shared space is: 0.0107\n"
     ]
    }
   ],
   "source": [
    "top_k_similarities, top_k_indices = torch.topk(similarities.squeeze(), k=1)\n",
    "f_end_index = top_k_indices[0].item()\n",
    "f_end_similarity = top_k_similarities[0].item()\n",
    "\n",
    "print(\n",
    "    f\"in MLP layer, the most related visual feature (f_end) index is: {f_end_index}\"\n",
    ")\n",
    "print(f\"cosine similarity in shared space is: {f_end_similarity:.4f}\")\n",
    "\n",
    "feature_idx = f_end_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522fcae",
   "metadata": {},
   "source": [
    "# Step 4: Circuit analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_cache(model_input, model):\n",
    "    \"\"\"Run the batch through the model to get activations\"\"\"\n",
    "    _, cache = model.run_with_cache(model_input)\n",
    "    return cache\n",
    "\n",
    "\n",
    "def get_feature_activations(tc, cache):\n",
    "    \"\"\"Compute the activation given a cache. If cache is not provided, run the model with cache.\n",
    "    we only need the activations of the hook point, so here use .encode() to get the activations instead of a forward pass.\n",
    "    \"\"\"\n",
    "    # _, cache = model.run_with_cache(model_input, names_filter=tc.cfg.hook_point)\n",
    "    hook_point_activation = cache[tc.cfg.hook_point].to(DEVICE)\n",
    "\n",
    "    # Calculate the transcoder features for the batch\n",
    "    _, feature_acts, *_ = tc.encode(hook_point_activation)\n",
    "\n",
    "    return feature_acts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 49152])\n",
      "torch.Size([49152])\n"
     ]
    }
   ],
   "source": [
    "cache = run_with_cache(img_tensor.to(DEVICE).unsqueeze(0), model_v)\n",
    "\n",
    "feature_activations = get_feature_activations(tc_10, cache)\n",
    "print(feature_activations.shape)\n",
    "# the shape is (sample_num, context_size, feature_num)\n",
    "feature_activations = feature_activations[0, 0, :]\n",
    "print(feature_activations.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830ff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 feature indices: [26500, 14518, 7309, 5010, 22339, 27913, 2193, 27101, 25734, 46014]\n",
      "Top 10 feature values: [1.764027  1.811428  1.8416208 1.8829956 1.8862857 1.8873948 1.9148407\n",
      " 2.0671937 2.0717473 5.3744574]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "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",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "hc7EPjloaD+VQPc9cUsZPjSnID8nCRo/XHmcP4bXPT6Z4tc+sjRTP2cAZD9QdGU+3weLPnIPeT6f8VA/dfFNP91akT8iDVM/2X6SP5IBqj7nfSw+JYhHPQRm5T2/WFs/N8IiP7K09z4L3BA/eimWPoAaTj54bQ4/rtiFPzdJWD+zW6g//XzuPhcqvD7FC0g/2FwsP4AZ9T9k0E0+WjrvPo5JIz/ts4I97O3rPctmkT8E2rg+SEvkPimMiD3rXoE/bjiyPsQaLz+Dbi8+kICmPYsGzD9kp6o9jhW8PuFqvz7FN4I/Kco6P0VSjD9iWA8/LCqqP1xAnj/t1I49LBYtPwT3jz+CBqU+tHFpPnQnUj9gRx4/HcQNPpbzDD7COs4+3r2ePhlHWT/H8AA/ZuNiPq4trD+gfpI+4pTrPj45zD4ABvE/gLdVPkoPoD6Ifkw9FbHGPY/abz+WmEg+PBaAPwRRoT/KPMQ/lOi9PcYHIT+t4VU+XaZCP+f7gD4Qv688oTJNPnBdWz8czB09KiuXP1/kij4Gqlc/Gap7P+YsOD+he4U/LIHRP4AQGD/eJOg+7WgzP/fVYD+Cua49v8m2PVJsuT4X+ms/URiJPzv7tj5Nx1A+O7rrP96UYD/zwrA//TakP9xI8D4BX5c+NX4ZP0eTkT9zmGY/JbKtPznYrT3WSRA/ygaWP7c5qD8dKAU/tl6IP5JfxT5k1iE/O35eP6Ddtj4IXuo9XNjMPjlJnT4NcYw9NpisPeSdlj38Ie89m4+gPhwfTT8RjZE+xXyWPZugbT/5UY8+tgYDPzfJ3T4mbzo+FnnBP75TFz9kMbI+aEJJP13sBj8i65g+Ux8mP8+V1D/QO8k+PWnUPu2qgD8j9Ms+y9KRP0ObjT8spAc9GFYxPi/5Oj80IV4+Vl13Pp1+QT9eLbI99R+8P/qGvT5rYTA/UpttP0KF/D46uJY/wJMWP27o8T6q3Lg+l704PyjwDz9tj4Q+gAFIP1Vdoz/KL4w/9hbIPnyFJT8oqgI/5jkePxvaUj/5anY+di50P0JGGj9SoVc/rQy0Pa/UIz+cc2U/K88APx376j5BBR8/Tq4jP2HJGD9oqYc/cK1bPR47Oz4R/oA+aep8P4CA/TxnBLQ+1D6gPqDbQz9yTZw+Oip1Pvs0CD8vyYk+EcrUPtLpET/3B1s/e9jtPt/c5z8RtbI/qY4oP3RFGj8oiQU/UVhlPsZ12D2XZ7I/LRFRP+54Bj9qvlI/JXeBP6yTXDzHz1g+BSYjP4pKEz/+Vqc+HIivP3GUnz6oJSU/4UqsPsoIUz4awic/9vqRPn5x0D5Iqis/0CqJP29sOD9SUDI/gc9OP8WLej7kyKc+8Cx1PfywsD+YQok/wf70Pa9QXT/ib7A+zHYVPySenz/YQCA/yh1/P/jgtz7pvho/nFaXP/MUsj8R8AY/M6N5PowdNT7qByo/pXNcP+o6pz6SaQY+YmgNPpXJbT9QFaU/eFgDP+vBsT5QgzQ/ht5ePXPhKT9MAF0/mFQzP2A/gT8JL9s+oPhQP3ddmD06Ago/NqrMPjYJED99cRw/OeBQPpSnqD6KWHk9YybVP7bbVz+XrGU/OP8RPwB+7z580xc/Fp9eP8A5jj/dHDg/6GkKP73NFj8jo6s9lpoYP/+GUz9LnfM+rxW1Pgx7WT9Za0k/B74kP87w3z5yB4o++vHDPc/33T5EcKw+kbglP0KVvD45uGM+PrqgPpgMgD+33O4+NCkwPjicPj8o1z0/YTS1PiNSLT/HHQM/4D3EPkY/nz84haE+RlLwPuR/Az8EMC4+H2V6P07IPT9JUJI+PkeLPk62BD9DTiw/kg1QP3wNnjwGsF0/+ErUPB/lmD9ULxk9tW7GPZvZ5D5vqKM/z3HxPw/f7j6UuRY/fEz0PmRxzD/brqw/t5DYPqqBGj7ZZos+HrW9PjYe7j56ZD4/2Z+PPpf4dj9R7AA/1uKxPRBLqj4uDUY+lTQaP28F8z4kj+0+DXqYP5L5VT8VBLk/KcODPjbJhzzIqgU/IC9sP+P8XT9KRrc/7jxSP4BTFT9+i78+PykbP/n6uT5270M/5GTTPiaECz+o3TM/wh2mP5lO2T5U4Ys9vQG0PiCAfT/PHHU+51svPboFeT/klmo/1IXAPUcfWT4hwMM97VuePpTgMT/Y5qc/sBbBPlyzAz9juTg/S7/cPQzNqD6QN1Q+V5/kPoKXBEDovqE+iMYmPrI5ijx43so/OOoZP/ykKT0GSD8/JtxtPuxanz0c+8Y88V2lP4BKwD6+OWs9F3oYP49Xkz5KiyU/o8vhPwodED8vAB4/CIFiP36xuj3MlIk+dxw2P+dMBED3YgM/Lc2VPhghtz7GX00+p071PqtRhT1Zd5g+cL4SP5WK3D98ShM/4AEwPtisND5DCgQ/mTwDP9xBvD760S0/J5bxPyXE6T5I4SQ+3u4gP+/Wwj79xXI+v7NoPyprLT8i1sg/tqjYPhR9/z5cvRM+54grPzK1oT9mEC4/c09OP2qEkT/XPIw/yrvePfXfbz4nL7g+fiRpPpgAIT94/Mw9DT41P6CoED7fFlU+Z/uePhWKND+8cxA/+grYPuEHLj/Q/20+2dVZP/eSzT7WpR8+4VdPPw6bFz/dOQc+G8C9Pq7kLT/iIww+z78AP1Gs3j1kZTE/+aUBPyc5PT8RGoU+LoisP+0Fhj+KdzM/wAYyP9Su4T4LLfw+Ou4sP/hWgz9CjCo/7jncPsSgQD+d37Q+PKckP3Q2qj97cmk/jgbOPp0uHT62Hs0/iTp8PpJWRz6w9h0/lzANP51rmT6ric4+6pixPn3eLz+YW0Y9rK1/PsoMiD4C3xk/AaAePx/zHj/mQ0g+8w4CP78/ez8e8YA+24TDP6nVLj98eDk+nghOP/VvDD+/Kow+xhqMP+L5Fz88HS0/Z7lmPyAS5zw9GJ4+ps6MPg3X2D4gqcs+xjb9PUOXQD9dRoA/Q9/ZPoBO6j4SXpM/z0mSPweP3j6NJGk/B2NPP95BYz4kQ0U9b8RMPi1Wgj+39L0+MmTLPvXbPD7eR4Y+xxCVPpOQ2T5gir8/24RlPwa4hD5KyG4+5Bk8P489mT5+O2s/v/74PZodlz9iH5k+Dtc8P8IdIj/3rBs/SpjmPsUBjD560GE/I8CDPk7jjD9qlPo+hx8CP9z41j5ICDU8GMOoPwvjUD5c6kk+YB8bP4WYQT+B7YU+4kxJP+p23T4lpd4/mq4EP1wdLj+LhNM+auI6Pjpw6j1qymY/ZVI0P5L0iD/rItg9IgDXPTaTeD6KexU/4NgeP3P7TD0fAlw+WoTRPejabD7Ne0M/1tuaPczT9j4NVxE+/y1qP6QZpz1MPo49d3OqPv0TqD9obN08+otaP5jj6z4NdWI/W2y1P+2AHT/31wI/Pd8fP4A18j6YaOc+lPa6PlhGqz3el8I++fo6PzaUjD67Nfc+3oadPjo7Aj/Qoq8+Tj1bP9B/cj3QnRI/tJiDPjohNz+iAx8+n5u5PxZB3z3OfDw/LubJPm6YCz8uLG4/biysPz/xwj56nq8/T9GEP9a3RD+6LRk/eZ78PovgNj9+j60+Mi8YPoMHiz/rqRQ9ogHEPbglGT2FaKY/IrqoPVbFEz7LHSo+V2QcPh0fBz5nIUI/mRiqP08Clz9UtVs/2XlKPjpBgD6GtKE+NX2GPnEbsz6WJBg/WC4/P8mEkj8pyZo+wspaP7KGfz+4Xp4/sDw6P1R2VD4CMqY/HdIkPrf6bD3PP7Q/O/2qP+AUAz9mwVU+CEJyP6vmzT7HZSY+D27wPosSuT7mzd8+Dtq9PmK+Ij/AETU/oOs5PiSk4j6+vZs/uIsLP/Mgvj7BORc/u+CAP4FPST/scTA/0dtPPkuUBD8oExI/CSeOPwuuHj/52UA++Vs1PzUdEz8h9Jw/DwmWPmWCVT4tV1o/u50NP3tQ4T8i2so+ANYGP9ZFuD6O+6tAfjHcPdQrXT7B9xM/OR+KP0qWRj/OI0g+2tNIP8EEsz7F4NI/jIfxPn9FQj8Q9TE/eQ8FPz47hz7KUd0+LrA3Px7umD8N14M86SMQP3hPkT5NC1M/lp2YP9T52T3Hrkg/5mtTPka7hj5jGh4+0FifPpRJsD8sVDs/jp1aPlt5iz/uiZQ/8LNDP54Nxz8xTrI9zCZiPzHpWj+B73M/Qf6AP/7rGD9zRgs/",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "red",
          "size": 8
         },
         "mode": "markers+text",
         "showlegend": false,
         "text": [
          "26500",
          "14518",
          "7309",
          "5010",
          "22339",
          "27913",
          "2193",
          "27101",
          "25734",
          "46014"
         ],
         "textfont": {
          "size": 8
         },
         "textposition": "top center",
         "type": "scatter",
         "x": {
          "bdata": "hGcAALY4AACNHAAAkhMAAENXAAAJbQAAkQgAAN1pAACGZAAAvrMAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "o8vhP9/c5z87uus/AAbxP89x8T8nlvE/gBn1P+dMBECClwRAjvurQA==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 400,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "plot_bgcolor": "rgba(255,255,255,1)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Feature Activations"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "rgba(0,0,0,0.3)",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "Feature Index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "rgba(0,0,0,0.3)",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "Feature Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_indices, _ = plot_act_distribution(feature_activations, n_top=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27fa31a",
   "metadata": {},
   "source": [
    "**Here, we are delighted to see that the most activated feature for the image is feature 46014, which is just the feature we find for the text embedding of label!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf9a79",
   "metadata": {},
   "source": [
    "Now let's begin our circuit analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2cab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrow from transcoder_circuits/circuit_analysis.py:\n",
    "# https://github.com/jacobdunefsky/transcoder_circuits.git\n",
    "\n",
    "import copy\n",
    "import enum\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "# define some classes\n",
    "\n",
    "\n",
    "class ComponentType(enum.Enum):\n",
    "    MLP = \"mlp\"\n",
    "    ATTN = \"attn\"\n",
    "    EMBED = \"embed\"\n",
    "\n",
    "    # error terms\n",
    "    TC_ERROR = \"tc_error\"  # error due to inaccurate transcoders\n",
    "    PRUNE_ERROR = (\n",
    "        \"prune_error\"  # error due to only looking at top paths in graph\n",
    "    )\n",
    "    BIAS_ERROR = \"bias_error\"  # account for bias terms in transcoders\n",
    "\n",
    "\n",
    "class FeatureType(enum.Enum):\n",
    "    NONE = \"none\"\n",
    "    SAE = \"sae\"\n",
    "    TRANSCODER = \"tc\"\n",
    "\n",
    "\n",
    "class ContribType(enum.Enum):\n",
    "    RAW = \"raw\"\n",
    "    ZERO_ABLATION = \"zero_ablation\"\n",
    "\n",
    "\n",
    "# Component: an individual component (e.g. an attn head or a transcoder feature)\n",
    "@dataclass\n",
    "class Component:\n",
    "    layer: int\n",
    "    component_type: ComponentType\n",
    "\n",
    "    token: Optional[int] = None\n",
    "\n",
    "    attn_head: Optional[int] = None\n",
    "\n",
    "    feature_type: Optional[FeatureType] = None\n",
    "    feature_idx: Optional[int] = None\n",
    "\n",
    "    def __str__(self, show_token=True):\n",
    "        retstr = \"\"\n",
    "        feature_type_str = \"\"\n",
    "\n",
    "        base_str = f\"{self.component_type.value}{self.layer}\"\n",
    "        attn_str = (\n",
    "            \"\"\n",
    "            if self.component_type != ComponentType.ATTN\n",
    "            else f\"[{self.attn_head}]\"\n",
    "        )\n",
    "\n",
    "        feature_str = \"\"\n",
    "        if self.feature_type is not None and self.feature_idx is not None:\n",
    "            feature_str = f\"{self.feature_type.value}[{self.feature_idx}]\"\n",
    "\n",
    "        token_str = \"\"\n",
    "        if self.token is not None and show_token:\n",
    "            token_str = f\"@{self.token}\"\n",
    "\n",
    "        retstr = \"\".join([base_str, attn_str, feature_str, token_str])\n",
    "        return retstr\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Component object {self!s}>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a feature vector first\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FeatureVector:\n",
    "    component_path: List[Component]\n",
    "    vector: torch.Tensor\n",
    "    layer: int\n",
    "    sublayer: str\n",
    "    token: Optional[int] = None\n",
    "    contrib: Optional[float] = None\n",
    "    contrib_type: Optional[ContribType] = None\n",
    "    error: float = 0.0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.token is None and len(self.component_path) > 0:\n",
    "            self.token = self.component_path[-1].token\n",
    "        if self.layer is None and len(self.component_path) > 0:\n",
    "            self.layer = self.component_path[-1].layer\n",
    "\n",
    "    # note: str(FeatureVector) should return a string that uniquely identifies a feature direction (e.g. for use in a causal graph)\n",
    "    # (this is distinct from a unique feature *vector*, by the way)\n",
    "    def __str__(self, show_full=True, show_contrib=True, show_last_token=True):\n",
    "        retstr = \"\"\n",
    "        token_str = (\n",
    "            \"\"\n",
    "            if self.token is None or not show_last_token\n",
    "            else f\"@{self.token}\"\n",
    "        )\n",
    "        if len(self.component_path) > 0:\n",
    "            if show_full:\n",
    "                retstr = \"\".join(\n",
    "                    x.__str__(show_token=False)\n",
    "                    for x in self.component_path[:-1]\n",
    "                )\n",
    "            retstr = \"\".join(\n",
    "                [\n",
    "                    retstr,\n",
    "                    self.component_path[-1].__str__(show_token=False),\n",
    "                    token_str,\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            retstr = f\"*{self.sublayer}{self.layer}{token_str}\"\n",
    "        if show_contrib and self.contrib is not None:\n",
    "            retstr = \"\".join([retstr, f\": {self.contrib:.2}\"])\n",
    "        return retstr\n",
    "\n",
    "    def __repr__(self):\n",
    "        contrib_type_str = (\n",
    "            \"\"\n",
    "            if self.contrib_type is None\n",
    "            else f\" contrib_type={self.contrib_type.value}\"\n",
    "        )\n",
    "        return f\"<FeatureVector object {self!s}, sublayer={self.sublayer}{contrib_type_str}>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfaa40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def make_transcoder_feature_vector(\n",
    "    sae, feature_idx, use_encoder=True, token=0\n",
    ") -> FeatureVector:\n",
    "    \"\"\"Build a feature vector for a given transcoder feature index.\n",
    "    Args:\n",
    "        sae: the transcoder model\n",
    "        feature_idx: the index of the feature\n",
    "        use_encoder: output encoder or decoder feature\n",
    "        token: the token index. Since we are building for image input, we pay attentiont to the CLS token, so we set token to 0.\n",
    "    Returns:\n",
    "        a FeatureVector object\n",
    "    \"\"\"\n",
    "\n",
    "    hook_point = (\n",
    "        sae.cfg.hook_point\n",
    "        if (use_encoder or not sae.cfg.is_transcoder)\n",
    "        else sae.cfg.out_hook_point\n",
    "    )\n",
    "    layer = (\n",
    "        sae.cfg.hook_point_layer\n",
    "        if (use_encoder or not sae.cfg.is_transcoder)\n",
    "        else sae.cfg.out_hook_point_layer\n",
    "    )\n",
    "    feature_type = (\n",
    "        FeatureType.SAE if not sae.cfg.is_transcoder else FeatureType.TRANSCODER\n",
    "    )\n",
    "    vector = (\n",
    "        sae.W_enc[:, feature_idx] if use_encoder else sae.W_dec[feature_idx]\n",
    "    )\n",
    "    vector = torch.clone(vector.detach())\n",
    "    vector.requires_grad = False\n",
    "    vector.requires_grad_(False)\n",
    "    if \"resid_mid\" in hook_point or (\n",
    "        \"normalized\" in hook_point and \"ln2\" in hook_point\n",
    "    ):\n",
    "        # currently, we treat ln2normalized as resid_mid\n",
    "        # this is kinda ugly, but because we account for layernorm constants in later\n",
    "        #  functions, this does work now\n",
    "        sublayer = \"resid_mid\"\n",
    "        component_type = ComponentType.MLP\n",
    "    elif \"resid_pre\" in hook_point:\n",
    "        sublayer = \"resid_pre\"\n",
    "        component_type = ComponentType.ATTN\n",
    "    elif \"mlp_out\" in hook_point:\n",
    "        sublayer = \"mlp_out\"\n",
    "        component_type = ComponentType.MLP\n",
    "    elif \"resid_post\" in hook_point:\n",
    "        sublayer = \"resid_post\"\n",
    "        component_type = ComponentType.ATTN\n",
    "\n",
    "    my_feature = FeatureVector(\n",
    "        component_path=[\n",
    "            Component(\n",
    "                layer=layer,\n",
    "                component_type=component_type,\n",
    "                token=token,\n",
    "                feature_type=feature_type,\n",
    "                feature_idx=feature_idx,\n",
    "            )\n",
    "        ],\n",
    "        layer=layer,\n",
    "        sublayer=sublayer,\n",
    "        vector=vector,\n",
    "    )\n",
    "\n",
    "    return my_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0ed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp10tc[46014]@0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector = make_transcoder_feature_vector(tc_10, feature_idx)\n",
    "print(feature_vector)\n",
    "feature_vector.vector.shape\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9638b53c",
   "metadata": {},
   "source": [
    "old attn head algorithm\n",
    "\n",
    "from transformer_lens.utils import get_act_name, to_numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_attn_head_contribs(model, cache, layer, range_normal):\n",
    "\tsplit_vals = cache[get_act_name('v', layer)]\n",
    "\tattn_pattern = cache[get_act_name('pattern', layer)]\n",
    "\n",
    "    # 'b h d s': attn_pattern with dimensions (batch, head, destination_pos, source_pos).\n",
    "    # 'b s h f': split_vals with dimensions (batch, source_pos, head, d_head).\n",
    "    # The einsum operation multiplies the attention scores with the corresponding value vectors. \n",
    "    # The result, weighted_vals, gives you the value from each source position, \n",
    "    # weighted by the attention from the destination position, for each head.\n",
    "\t#'batch head dst src, batch src head d_head -> batch head dst src d_head'\n",
    "\tweighted_vals = torch.einsum(\n",
    "\t\t'b h d s, b s h f -> b h d s f',\n",
    "\t\tattn_pattern, split_vals\n",
    "\t)\n",
    "\n",
    "'batch head dst src d_head, head d_head d_model -> batch head dst src d_model'\n",
    "\tweighted_outs = torch.einsum(\n",
    "\t\t'b h d s f, h f m -> b h d s m',\n",
    "\t\tweighted_vals, model.W_O[layer]\n",
    "\t)\n",
    "\n",
    "'batch head dst src d_model, d_model -> batch head dst src'\n",
    "\tcontribs = torch.einsum(\n",
    "\t\t'b h d s m, m -> b h d s',\n",
    "\t\tweighted_outs, range_normal\n",
    "\t)\n",
    "\n",
    "\treturn contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50ce87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual.transformer.resblocks[0].attn.out_proj.weight.shape\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8af8157",
   "metadata": {},
   "source": [
    "from transformer_lens.utils import get_act_name, to_numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_attn_head_contribs(model, cache, layer, range_normal):\n",
    "    \"\"\"\n",
    "    Calculates the contribution of each attention head to a specific direction (range_normal)\n",
    "    in the residual stream. Adapted for open_clip ViT.\n",
    "    \"\"\"\n",
    "    # Get the value vectors (after W_V projection) for each head and token\n",
    "    # cache['v', layer] has shape [batch, seq_len, num_heads, d_head]\n",
    "    split_vals = cache[get_act_name('v', layer)]\n",
    "    \n",
    "    # Get the attention pattern (softmax output)\n",
    "    # shape: [batch, num_heads, dst_pos, src_pos]\n",
    "    attn_pattern = cache[get_act_name('pattern', layer)]\n",
    "    \n",
    "    # Get the output weight matrix for this layer\n",
    "    # shape: [d_model, num_heads * d_head] -> reshape to [d_model, num_heads, d_head]\n",
    "    W_O = model.visual.transformer.resblocks[layer].attn.out_proj.weight\n",
    "    d_model = model.visual.transformer.resblocks[layer].attn.d_model\n",
    "    d_head = model.visual.transformer.resblocks[layer].attn.d_head\n",
    "    num_heads = model.visual.transformer.resblocks[layer].attn.num_heads\n",
    "    W_O_reshaped = W_O.reshape(d_model, num_heads, d_head)\n",
    "\n",
    "\n",
    "    # Calculate the output of each head by combining values with attention scores\n",
    "    # b=batch, h=head, d=dst_pos, s=src_pos, f=d_head\n",
    "    # We want to get the output of each head for each destination token\n",
    "    # attn_pattern: [b, h, d, s]\n",
    "    # split_vals: [b, s, h, f] \n",
    "    # Let's align them:\n",
    "    split_vals_permuted = split_vals.permute(0, 2, 1, 3) # -> [b, h, s, f]\n",
    "    \n",
    "    # For each destination token 'd', compute weighted sum of value vectors\n",
    "    # weighted_vals shape: [b, h, d, f]\n",
    "    weighted_vals = torch.einsum('bhds,bhsf->bhdf', attn_pattern, split_vals_permuted)\n",
    "    \n",
    "    # Project the head outputs back to the model dimension\n",
    "    # weighted_outs shape: [b, h, d, m] where m=d_model\n",
    "    weighted_outs = torch.einsum('bhdf,mhf->bhdm', weighted_vals, W_O_reshaped)\n",
    "\n",
    "    # Finally, project these outputs onto our target direction (range_normal)\n",
    "    # This gives the scalar contribution of each head at each destination token\n",
    "    # contribs shape: [b, h, d]\n",
    "    contribs = torch.einsum('bhdm,m->bhd', weighted_outs, range_normal)\n",
    "    \n",
    "    # We also need the source token contributions for path analysis\n",
    "    # Let's re-calculate to get the full [b, h, d, s] contribution matrix\n",
    "    # This matches the original function's output shape for compatibility\n",
    "    # weighted_outs_full shape: [b, h, d, s, m]\n",
    "    weighted_outs_full = torch.einsum('bhds,bhsf,mhf->bhsdm', attn_pattern, split_vals_permuted, W_O_reshaped)\n",
    "    contribs_full = torch.einsum('bhsdm,m->bhsd', weighted_outs_full, range_normal)\n",
    "    \n",
    "    return contribs_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ef272",
   "metadata": {},
   "source": [
    "## Build the paths\n",
    "We will use the greedy path finding algorithm to see which features contribute most to the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name, to_numpy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_attn_head_contribs(model, cache, layer_idx, range_normal):\n",
    "    \"\"\"\n",
    "    Calculate the contribution of each attention head from each source token to each destination token, adapted for OpenCLIP ViT.\n",
    "\n",
    "    Args:\n",
    "        model: the visual model (e.g., model_v)\n",
    "        cache: the cache of all the layers\n",
    "        layer_idx: the current layer to analyze\n",
    "        range_normal: the target direction vector (from a higher-level feature_vector)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape [batch, num_heads, dst_pos, src_pos], representing the contribution scores\n",
    "    \"\"\"\n",
    "    # 1. from cache, get v_acts and pattern\n",
    "    # v_acts.shape: [batch, seq_len, num_heads, d_head]\n",
    "    v_acts = cache[get_act_name(\"v\", layer_idx)]\n",
    "\n",
    "    # pattern.shape: [batch, num_heads, dst_pos, src_pos]\n",
    "    pattern = cache[get_act_name(\"pattern\", layer_idx)]\n",
    "\n",
    "    # 2. get W_O and reshape for head-wise multiplication\n",
    "    attn_block = model.visual.transformer.resblocks[layer_idx].attn\n",
    "    n_heads = attn_block.num_heads\n",
    "    d_model = attn_block.embed_dim\n",
    "    d_head = d_model // n_heads\n",
    "\n",
    "    W_O = attn_block.out_proj.weight.reshape(\n",
    "        n_heads, d_head, d_model  # d_head_out  # d_model\n",
    "    )\n",
    "\n",
    "    # 3. calculate contribs\n",
    "    # 'bshf,hfm,b hds,m->bhds'\n",
    "    # b: batch, s: src_pos, h: head, f: d_head, m: d_model, d: dst_pos\n",
    "    contribs = torch.einsum(\n",
    "        \"bshf,hfm,bhds,m->bhds\", v_acts, W_O, pattern, range_normal\n",
    "    )\n",
    "\n",
    "    return contribs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c001ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_transcoder_ixg(\n",
    "    transcoder,\n",
    "    cache,\n",
    "    range_normal,\n",
    "    input_layer,\n",
    "    input_token_idx,\n",
    "    return_numpy=True,\n",
    "    is_transcoder_post_ln=True,\n",
    "    return_feature_activs=True,\n",
    "):\n",
    "    pulledback_feature = transcoder.W_dec @ range_normal\n",
    "    if is_transcoder_post_ln:\n",
    "        act_name = get_act_name(\"normalized\", input_layer, \"ln2\")\n",
    "    else:\n",
    "        act_name = get_act_name(\"resid_mid\", input_layer)\n",
    "\n",
    "    feature_activs = transcoder.encode(cache[act_name])[1][0, input_token_idx]\n",
    "    pulledback_feature = pulledback_feature * feature_activs\n",
    "    if return_numpy:\n",
    "        pulledback_feature = to_numpy(pulledback_feature)\n",
    "        feature_activs = to_numpy(feature_activs)\n",
    "\n",
    "    if not return_feature_activs:\n",
    "        return pulledback_feature\n",
    "    else:\n",
    "        return pulledback_feature, feature_activs\n",
    "\n",
    "\n",
    "# # get the mean input-times-gradient vector over a dataset of tokens\n",
    "# @torch.no_grad()\n",
    "# def get_mean_ixg(model, tokens_arr, range_transcoder, range_feature_idx, transcoder, token_idxs=None, batch_size=64, do_sum_count=False):\n",
    "#     act_name = transcoder.cfg.hook_point\n",
    "#     layer = transcoder.cfg.hook_point_layer\n",
    "\n",
    "#     range_normal = range_transcoder.W_enc[:, range_feature_idx]\n",
    "#     pulledback_feature = transcoder.W_dec @ range_normal\n",
    "\n",
    "\n",
    "#     if token_idxs is None:\n",
    "#         tokens_gen = tqdm.tqdm(range(0, tokens_arr.shape[0], batch_size))\n",
    "#     else:\n",
    "#         tokens_gen = tqdm.tqdm(token_idxs)\n",
    "\n",
    "#     if not do_sum_count:\n",
    "#         mean_ixgs = []\n",
    "#     else:\n",
    "#         ixgs_sum = np.zeros(transcoder.W_enc.shape[1])\n",
    "#         ixgs_count = np.zeros(transcoder.W_enc.shape[1])\n",
    "\n",
    "#     for t in tokens_gen:\n",
    "#         if token_idxs is not None:\n",
    "#             example_idx, token_idx = t\n",
    "#             with torch.no_grad():\n",
    "#                 _, cache = model.run_with_cache(tokens_arr[example_idx, :token_idx+1], stop_at_layer=layer+1, names_filter=[\n",
    "#                     act_name\n",
    "#                 ])\n",
    "#                 acts = cache[act_name]\n",
    "#                 feature_activs = transcoder.encode(acts)[1][0, token_idx]\n",
    "#                 cur_ixg = (pulledback_feature * feature_activs)[None]\n",
    "#         else:\n",
    "#             i = t\n",
    "#             with torch.no_grad():\n",
    "#                 _, cache = model.run_with_cache(tokens_arr[i:i+batch_size], stop_at_layer=layer+1, names_filter=[\n",
    "#                     act_name\n",
    "#                 ])\n",
    "#                 acts = cache[act_name]\n",
    "#                 feature_activs = transcoder.encode(acts)[1].reshape(-1, transcoder.W_enc.shape[1])\n",
    "\n",
    "#                 cur_ixg = torch.einsum('i, ji -> ji', pulledback_feature, feature_activs)\n",
    "\n",
    "#         if not do_sum_count:\n",
    "#             mean_ixgs.append(np.mean(to_numpy(cur_ixg), axis=0))\n",
    "#         else:\n",
    "#             ixgs_sum += to_numpy(cur_ixg).sum(axis=0)\n",
    "#             ixgs_count += np.abs(to_numpy(cur_ixg)>0).sum(axis=0)\n",
    "\n",
    "#     if do_sum_count:\n",
    "#         ixgs_count[ixgs_count == 0] = 1\n",
    "#         return ixgs_sum/ixgs_count, ixgs_count/len(token_idxs)\n",
    "#     else:\n",
    "#         return np.mean(mean_ixgs, axis=0)\n",
    "\n",
    "\n",
    "# approximate layernorms as constants when propagating feature vectors backward\n",
    "# for theoretical motivation, see the LayerNorm section of\n",
    "# \thttps://www.neelnanda.io/mechanistic-interpretability/attribution-patching\n",
    "@torch.no_grad()\n",
    "def get_ln_constant(\n",
    "    model, cache, vector, layer, token, is_ln2=False, recip=False\n",
    "):\n",
    "    x_act_name = (\n",
    "        get_act_name(\"resid_mid\", layer)\n",
    "        if is_ln2\n",
    "        else get_act_name(\"resid_pre\", layer)\n",
    "    )\n",
    "    x = cache[x_act_name][0, token]\n",
    "\n",
    "    y_act_name = get_act_name(\"normalized\", layer, \"ln2\" if is_ln2 else \"ln1\")\n",
    "    y = cache[y_act_name][0, token]\n",
    "\n",
    "    if torch.dot(vector, x) == 0:\n",
    "        return torch.tensor(0.0)\n",
    "    return (\n",
    "        torch.dot(vector, y) / torch.dot(vector, x)\n",
    "        if not recip\n",
    "        else torch.dot(vector, x) / torch.dot(vector, y)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_top_transcoder_features(\n",
    "    model, transcoder, cache, feature_vector, layer, k=5\n",
    "):\n",
    "    my_token = (\n",
    "        feature_vector.token\n",
    "        if feature_vector.token >= 0\n",
    "        else cache[get_act_name(\"resid_pre\", 0)].shape[1] + feature_vector.token\n",
    "    )\n",
    "    is_transcoder_post_ln = (\n",
    "        \"ln2\" in transcoder.cfg.hook_point\n",
    "        and \"normalized\" in transcoder.cfg.hook_point\n",
    "    )\n",
    "\n",
    "    # compute error\n",
    "    if is_transcoder_post_ln:\n",
    "        act_name = get_act_name(\"normalized\", layer, \"ln2\")\n",
    "    else:\n",
    "        act_name = get_act_name(\"resid_mid\", layer)\n",
    "    transcoder_out = transcoder.encode(cache[act_name])[0][0, my_token]\n",
    "    # mlp_out = model.blocks[layer].mlp(cache[act_name])[0, my_token]\n",
    "    mlp_out = model.visual.transformer.resblocks[layer].mlp(cache[act_name])[\n",
    "        0, my_token\n",
    "    ]\n",
    "\n",
    "    error = torch.dot(\n",
    "        feature_vector.vector, mlp_out - transcoder_out\n",
    "    ) / torch.dot(feature_vector.vector, mlp_out)\n",
    "\n",
    "    # compute pulledback feature\n",
    "    pulledback_feature, feature_activs = get_transcoder_ixg(\n",
    "        transcoder,\n",
    "        cache,\n",
    "        feature_vector.vector,\n",
    "        layer,\n",
    "        feature_vector.token,\n",
    "        return_numpy=False,\n",
    "        is_transcoder_post_ln=is_transcoder_post_ln,\n",
    "    )\n",
    "    top_contribs, top_indices = torch.topk(pulledback_feature, k=k)\n",
    "\n",
    "    top_contribs_list = []\n",
    "    for contrib, index in zip(top_contribs, top_indices):\n",
    "        vector = transcoder.W_enc[:, index]\n",
    "        vector = vector * (transcoder.W_dec @ feature_vector.vector)[index]\n",
    "\n",
    "        if is_transcoder_post_ln:\n",
    "            vector = vector * get_ln_constant(\n",
    "                model, cache, vector, layer, feature_vector.token, is_ln2=True\n",
    "            )\n",
    "\n",
    "        new_component = Component(\n",
    "            layer=layer,\n",
    "            component_type=ComponentType.MLP,\n",
    "            token=my_token,\n",
    "            feature_type=FeatureType.TRANSCODER,\n",
    "            feature_idx=index.item(),\n",
    "        )\n",
    "        top_contribs_list.append(\n",
    "            FeatureVector(\n",
    "                component_path=[new_component],\n",
    "                vector=vector,\n",
    "                layer=layer,\n",
    "                sublayer=\"resid_mid\",\n",
    "                contrib=contrib.item(),\n",
    "                contrib_type=ContribType.RAW,\n",
    "                error=error,\n",
    "            )\n",
    "        )\n",
    "    return top_contribs_list\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9d69eef",
   "metadata": {},
   "source": [
    "attn_block = model.visual.transformer.resblocks[10].attn\n",
    "d_model = attn_block.embed_dim\n",
    "n_heads = attn_block.num_heads\n",
    "d_head = d_model // n_heads\n",
    "# if ignore_bos:\n",
    "#     src_token = src_token + 1\n",
    "\n",
    "# W_O_head is used to project the feature vector to the head space\n",
    "W_O_head = attn_block.out_proj.weight.reshape(n_heads, d_head, d_model)[1, :, :]\n",
    "W_O_head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_top_contribs(\n",
    "    model,\n",
    "    transcoders,\n",
    "    cache,\n",
    "    feature_vector,\n",
    "    k=5,\n",
    "    ignore_bos=False,\n",
    "    only_return_all_scores=False,\n",
    "    cap=None,\n",
    "    filter=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get top contributions for a feature vector.\n",
    "    Adapted for a ViT model. It now uses get_attn_head_contribs for attention head calculations.\n",
    "    Args:\n",
    "        model: the CLIP model\n",
    "        transcoders: the transcoders\n",
    "        cache: the cache of all the layers\n",
    "        feature_vector: the feature vector\n",
    "        k: the number of top contributions to return\n",
    "        ignore_bos: whether to ignore the BOS token\n",
    "    \"\"\"\n",
    "    if feature_vector.sublayer == \"mlp_out\":\n",
    "        return get_top_transcoder_features(\n",
    "            model,\n",
    "            transcoders[feature_vector.layer],\n",
    "            cache,\n",
    "            feature_vector,\n",
    "            feature_vector.layer,\n",
    "            k=k,\n",
    "        )\n",
    "\n",
    "    my_layer = feature_vector.layer\n",
    "\n",
    "    # get MLP contribs\n",
    "    all_mlp_contribs = []\n",
    "    # go to all the previous layers\n",
    "    mlp_max_layer = my_layer + (\n",
    "        1 if feature_vector.sublayer == \"resid_post\" else 0\n",
    "    )\n",
    "    for cur_layer in range(mlp_max_layer):\n",
    "        cur_top_features = get_top_transcoder_features(\n",
    "            model, transcoders[cur_layer], cache, feature_vector, cur_layer, k=k\n",
    "        )\n",
    "        all_mlp_contribs = all_mlp_contribs + cur_top_features\n",
    "\n",
    "    # get attn contribs\n",
    "    all_attn_contribs = []\n",
    "    attn_max_layer = my_layer + (\n",
    "        1\n",
    "        if feature_vector.sublayer == \"resid_post\"\n",
    "        or feature_vector.sublayer == \"resid_mid\"\n",
    "        else 0\n",
    "    )\n",
    "    for cur_layer in range(attn_max_layer):\n",
    "        attn_contribs = get_attn_head_contribs(\n",
    "            model, cache, cur_layer, feature_vector.vector\n",
    "        )[0, :, feature_vector.token, :]\n",
    "        # if ignore_bos:\n",
    "        #     attn_contribs = attn_contribs[:, 1:]\n",
    "\n",
    "        if attn_contribs.numel() == 0:\n",
    "            print(f\"No attn contribs for layer {cur_layer}\")\n",
    "            continue\n",
    "\n",
    "        # here we get the top k attn contribs, they are scalars\n",
    "        top_attn_contribs_flattened, top_attn_contrib_indices_flattened = (\n",
    "            torch.topk(\n",
    "                attn_contribs.flatten(), k=np.min([k, len(attn_contribs)])\n",
    "            )\n",
    "        )\n",
    "        top_attn_contrib_indices = np.array(\n",
    "            np.unravel_index(\n",
    "                to_numpy(top_attn_contrib_indices_flattened),\n",
    "                attn_contribs.shape,\n",
    "            )\n",
    "        ).T\n",
    "\n",
    "        # here we get the top k attn contribs, they are vectors\n",
    "        for contrib, (head, src_token) in zip(\n",
    "            top_attn_contribs_flattened, top_attn_contrib_indices\n",
    "        ):\n",
    "            # adapted for ViT\n",
    "            attn_block = model.visual.transformer.resblocks[cur_layer].attn\n",
    "            d_model = attn_block.embed_dim\n",
    "            n_heads = attn_block.num_heads\n",
    "            d_head = d_model // n_heads\n",
    "            # if ignore_bos:\n",
    "            #     src_token = src_token + 1\n",
    "\n",
    "            # W_O_head is used to project the feature vector to the head space\n",
    "            # W_O_head.shape: (d_head, d_model) = (64, 768)\n",
    "            W_O_head = attn_block.out_proj.weight.reshape(\n",
    "                n_heads, d_head, d_model\n",
    "            )[head, :, :]\n",
    "\n",
    "            # in openclip, W_Q, W_K, W_V is in in_proj_weight, we need to use .chunk(3)[2] to separate them.\n",
    "            # W_V_head.shape = (d_model, d_head) = (768, 64)\n",
    "            W_V_head = (\n",
    "                attn_block.in_proj_weight.chunk(3)[2]\n",
    "                .reshape(d_model, n_heads, d_head)\n",
    "                .permute(1, 0, 2)[head, :, :]\n",
    "            )\n",
    "\n",
    "            OV = W_V_head @ W_O_head  # shape: (d_model, d_model) = (768, 768)\n",
    "\n",
    "            # vector = model.OV[cur_layer, head] @ feature_vector.vector\n",
    "            vector = OV @ feature_vector.vector\n",
    "            attn_pattern = cache[get_act_name(\"pattern\", cur_layer)]\n",
    "            vector = (\n",
    "                vector * attn_pattern[0, head, feature_vector.token, src_token]\n",
    "            )\n",
    "            ln_constant = get_ln_constant(\n",
    "                model, cache, vector, cur_layer, src_token, is_ln2=False\n",
    "            )\n",
    "            vector = vector * ln_constant\n",
    "            if ln_constant.isnan():\n",
    "                print(\"Nan!\")\n",
    "\n",
    "            new_component = Component(\n",
    "                layer=cur_layer,\n",
    "                component_type=ComponentType.ATTN,\n",
    "                token=src_token,\n",
    "                attn_head=head,\n",
    "            )\n",
    "            new_feature_vector = FeatureVector(\n",
    "                component_path=feature_vector.component_path + [new_component],\n",
    "                vector=vector,\n",
    "                layer=cur_layer,\n",
    "                sublayer=\"resid_pre\",\n",
    "                contrib=contrib.item(),\n",
    "                contrib_type=ContribType.RAW,\n",
    "            )\n",
    "            all_attn_contribs.append(new_feature_vector)\n",
    "\n",
    "    # get embedding contribs\n",
    "    my_token = (\n",
    "        feature_vector.token\n",
    "        if feature_vector.token >= 0\n",
    "        else cache[get_act_name(\"resid_pre\", 0)].shape[1] + feature_vector.token\n",
    "    )\n",
    "    # my_token = feature_vector.token\n",
    "    embedding_contrib = FeatureVector(\n",
    "        component_path=feature_vector.component_path\n",
    "        + [\n",
    "            Component(\n",
    "                layer=0,\n",
    "                component_type=ComponentType.EMBED,\n",
    "                token=my_token,\n",
    "            )\n",
    "        ],\n",
    "        vector=feature_vector.vector,\n",
    "        layer=0,\n",
    "        sublayer=\"resid_pre\",\n",
    "        contrib=torch.dot(\n",
    "            cache[get_act_name(\"resid_pre\", 0)][0, feature_vector.token],\n",
    "            feature_vector.vector,\n",
    "        ).item(),\n",
    "        contrib_type=ContribType.RAW,\n",
    "    )\n",
    "\n",
    "    # get top contribs from all categories\n",
    "    all_contribs = all_mlp_contribs + all_attn_contribs + [embedding_contrib]\n",
    "\n",
    "    if filter is not None:\n",
    "        all_contribs = [x for x in all_contribs if filter.match(x)]\n",
    "\n",
    "    if cap is not None:\n",
    "        for i, contrib in enumerate(all_contribs):\n",
    "            if contrib.contrib > cap:\n",
    "                all_contribs[i].contrib = cap\n",
    "                all_contribs[i].contrib_type = ContribType.ZERO_ABLATION\n",
    "    all_contrib_scores = torch.tensor([x.contrib for x in all_contribs])\n",
    "    if only_return_all_scores:\n",
    "        return all_contrib_scores\n",
    "\n",
    "    _, top_contrib_indices = torch.topk(\n",
    "        all_contrib_scores, k=np.min([k, len(all_contrib_scores)])\n",
    "    )\n",
    "    return [all_contribs[i.item()] for i in top_contrib_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_get_top_paths(\n",
    "    model,\n",
    "    transcoders,\n",
    "    cache,\n",
    "    feature_vector,\n",
    "    num_iters=2,\n",
    "    num_branches=5,\n",
    "    ignore_bos=True,\n",
    "    do_raw_attribution=False,\n",
    "    filter=None,\n",
    "):\n",
    "    do_cap = not do_raw_attribution  # historical name change; TODO: refactor\n",
    "\n",
    "    all_paths = []\n",
    "    new_root = copy.deepcopy(feature_vector)\n",
    "\n",
    "    # deal with LN constant\n",
    "    # TODO: this is hacky and makes the assumption that if feature_vector is a transcoder feature, then it comes from the passed list of transcoders\n",
    "    if new_root.component_path[-1].feature_type == FeatureType.TRANSCODER:\n",
    "        tc = transcoders[new_root.layer]\n",
    "        if \"ln2.hook_normalized\" in tc.cfg.hook_point:\n",
    "            ln_constant = get_ln_constant(\n",
    "                model,\n",
    "                cache,\n",
    "                new_root.vector,\n",
    "                new_root.layer,\n",
    "                new_root.token,\n",
    "                is_ln2=True,\n",
    "            )\n",
    "            new_root.vector *= ln_constant\n",
    "        new_root.contrib = tc.encode(cache[tc.cfg.hook_point])[1][\n",
    "            0, new_root.token, new_root.component_path[-1].feature_idx\n",
    "        ].item()\n",
    "    cur_paths = [[new_root]]\n",
    "    for iter in range(num_iters):\n",
    "        new_paths = []\n",
    "        for path in cur_paths:\n",
    "            cur_feature = path[-1]\n",
    "            if cur_feature.layer == 0 and cur_feature.sublayer == \"resid_pre\":\n",
    "                continue\n",
    "\n",
    "            cap = None\n",
    "            if do_cap:\n",
    "                # Cap feature contribs at smallest transcoder feature activation\n",
    "                # This corresponds to calculating feature attribs by\n",
    "                #   zero-ablating the output of the feature\n",
    "                for cap_feature in path:\n",
    "                    if len(cap_feature.component_path) > 0 and (\n",
    "                        cap_feature.component_path[-1].feature_type\n",
    "                        == FeatureType.TRANSCODER\n",
    "                        or (\n",
    "                            cap_feature.component_path[-1].feature_type\n",
    "                            == FeatureType.SAE\n",
    "                            and (cap is None or cap_feature.contrib < cap)\n",
    "                        )\n",
    "                    ):\n",
    "                        cap = cap_feature.contrib\n",
    "\n",
    "            cur_top_contribs = get_top_contribs(\n",
    "                model,\n",
    "                transcoders,\n",
    "                cache,\n",
    "                cur_feature,\n",
    "                k=num_branches,\n",
    "                ignore_bos=ignore_bos,\n",
    "                cap=cap,\n",
    "                filter=filter,\n",
    "            )\n",
    "            new_paths = new_paths + [\n",
    "                path + [cur_top_contrib] for cur_top_contrib in cur_top_contribs\n",
    "            ]\n",
    "        _, top_new_path_indices = torch.topk(\n",
    "            torch.tensor([new_path[-1].contrib for new_path in new_paths]),\n",
    "            k=np.min([num_branches, len(new_paths)]),\n",
    "        )\n",
    "        cur_paths = [new_paths[i] for i in top_new_path_indices]\n",
    "        all_paths.append(cur_paths)\n",
    "    return all_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c85ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6309d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = greedy_get_top_paths(\n",
    "    model,\n",
    "    tc_list,\n",
    "    cache,\n",
    "    feature_vector,\n",
    "    num_iters=NUM_ITERS,\n",
    "    num_branches=15,\n",
    "    do_raw_attribution=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebde63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_paths(paths):\n",
    "    if len(paths) == 0:\n",
    "        return\n",
    "    if type(paths[0][0]) is list:\n",
    "        for i, cur_paths in enumerate(paths):\n",
    "            try:\n",
    "                print(f\"--- Paths of size {len(cur_paths[0])} ---\")\n",
    "            except:\n",
    "                continue\n",
    "            for j, cur_path in enumerate(cur_paths):\n",
    "                print(f\"Path [{i}][{j}]: \", end=\"\")\n",
    "                print(\n",
    "                    \" <- \".join(\n",
    "                        map(\n",
    "                            lambda x: x.__str__(\n",
    "                                show_full=False, show_last_token=True\n",
    "                            ),\n",
    "                            cur_path,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        for j, cur_path in enumerate(paths):\n",
    "            print(f\"Path [{j}]: \", end=\"\")\n",
    "            print(\n",
    "                \" <- \".join(\n",
    "                    map(\n",
    "                        lambda x: x.__str__(\n",
    "                            show_full=False, show_last_token=True\n",
    "                        ),\n",
    "                        cur_path,\n",
    "                    )\n",
    "                )\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe04be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paths of size 2 ---\n",
      "Path [0][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[37227]@0: 2.7\n",
      "Path [0][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[3300]@0: 2.7\n",
      "Path [0][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[44224]@0: 2.5\n",
      "Path [0][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[188]@0: 2.3\n",
      "Path [0][4]: mlp10tc[46014]@0: 5.4 <- mlp8tc[7053]@0: 2.1\n",
      "Path [0][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[1987]@0: 2.1\n",
      "Path [0][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[43817]@0: 2.0\n",
      "Path [0][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9\n",
      "Path [0][8]: mlp10tc[46014]@0: 5.4 <- mlp8tc[41884]@0: 1.7\n",
      "Path [0][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[42258]@0: 1.7\n",
      "Path [0][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[6684]@0: 1.6\n",
      "Path [0][11]: mlp10tc[46014]@0: 5.4 <- mlp8tc[13869]@0: 1.6\n",
      "Path [0][12]: mlp10tc[46014]@0: 5.4 <- mlp8tc[21658]@0: 1.5\n",
      "Path [0][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[31906]@0: 1.5\n",
      "Path [0][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[6886]@0: 1.5\n",
      "--- Paths of size 3 ---\n",
      "Path [1][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[37227]@0: 2.7 <- embed0@0: 2.1\n",
      "Path [1][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[43817]@0: 2.0 <- embed0@0: 1.9\n",
      "Path [1][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[1987]@0: 2.1 <- embed0@0: 1.5\n",
      "Path [1][3]: mlp10tc[46014]@0: 5.4 <- mlp8tc[41884]@0: 1.7 <- embed0@0: 1.5\n",
      "Path [1][4]: mlp10tc[46014]@0: 5.4 <- mlp8tc[7053]@0: 2.1 <- embed0@0: 1.4\n",
      "Path [1][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp7tc[46190]@0: 1.3\n",
      "Path [1][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[31906]@0: 1.5 <- embed0@0: 1.2\n",
      "Path [1][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[188]@0: 2.3 <- embed0@0: 1.2\n",
      "Path [1][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[31058]@0: 1.1\n",
      "Path [1][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp6tc[6360]@0: 1.0\n",
      "Path [1][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[6684]@0: 1.6 <- embed0@0: 0.98\n",
      "Path [1][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96\n",
      "Path [1][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[36664]@0: 0.87\n",
      "Path [1][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[44224]@0: 2.5 <- mlp7tc[6843]@0: 0.84\n",
      "Path [1][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[17621]@0: 0.83\n",
      "--- Paths of size 4 ---\n",
      "Path [2][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp6tc[6360]@0: 1.0 <- embed0@0: 2.4\n",
      "Path [2][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp7tc[46190]@0: 1.3 <- embed0@0: 2.3\n",
      "Path [2][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[17621]@0: 0.83 <- embed0@0: 1.1\n",
      "Path [2][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[44224]@0: 2.5 <- mlp7tc[6843]@0: 0.84 <- embed0@0: 1.1\n",
      "Path [2][4]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[31058]@0: 1.1 <- embed0@0: 1.0\n",
      "Path [2][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- embed0@0: 0.98\n",
      "Path [2][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[36664]@0: 0.87 <- embed0@0: 0.49\n",
      "Path [2][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp5tc[7438]@0: 0.21\n",
      "Path [2][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp6tc[6360]@0: 1.0 <- mlp3tc[23198]@0: 0.21\n",
      "Path [2][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp6tc[6360]@0: 1.0 <- mlp1tc[7317]@0: 0.2\n",
      "Path [2][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp2tc[3893]@0: 0.17\n",
      "Path [2][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp5tc[17135]@0: 0.16\n",
      "Path [2][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[17621]@0: 0.83 <- mlp7tc[44596]@0: 0.15\n",
      "Path [2][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp1tc[7317]@0: 0.14\n",
      "Path [2][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14\n",
      "--- Paths of size 5 ---\n",
      "Path [3][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- embed0@0: 1.3\n",
      "Path [3][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp6tc[6360]@0: 1.0 <- mlp3tc[23198]@0: 0.21 <- embed0@0: 0.28\n",
      "Path [3][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp2tc[3893]@0: 0.17 <- embed0@0: 0.22\n",
      "Path [3][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[17621]@0: 0.83 <- mlp7tc[44596]@0: 0.15 <- embed0@0: 0.22\n",
      "Path [3][4]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp5tc[7438]@0: 0.21 <- embed0@0: 0.19\n",
      "Path [3][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp5tc[17135]@0: 0.16 <- embed0@0: 0.18\n",
      "Path [3][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14\n",
      "Path [3][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13\n",
      "Path [3][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp0tc[40874]@0: 0.13\n",
      "Path [3][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp3tc[23198]@0: 0.12\n",
      "Path [3][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp0tc[16727]@0: 0.11\n",
      "Path [3][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp2tc[33043]@0: 0.11\n",
      "Path [3][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- attn0[5]@0: 0.11\n",
      "Path [3][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1\n",
      "Path [3][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp3tc[46689]@0: 0.099\n",
      "--- Paths of size 6 ---\n",
      "Path [4][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- embed0@0: 0.29\n",
      "Path [4][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp2tc[33043]@0: 0.11 <- embed0@0: 0.18\n",
      "Path [4][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp3tc[23198]@0: 0.12 <- embed0@0: 0.16\n",
      "Path [4][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- embed0@0: 0.15\n",
      "Path [4][4]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- embed0@0: 0.13\n",
      "Path [4][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp3tc[46689]@0: 0.099 <- embed0@0: 0.079\n",
      "Path [4][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp0tc[40874]@0: 0.13 <- embed0@0: 0.049\n",
      "Path [4][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp0tc[16727]@0: 0.11 <- embed0@0: 0.03\n",
      "Path [4][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- mlp0tc[43064]@0: 0.0078\n",
      "Path [4][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073\n",
      "Path [4][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- mlp0tc[366]@0: 0.0073\n",
      "Path [4][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp0tc[40874]@0: 0.0069\n",
      "Path [4][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp1tc[7317]@0: 0.0059\n",
      "Path [4][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp3tc[27504]@0: 0.0056\n",
      "Path [4][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp5tc[8363]@0: 0.0055\n",
      "--- Paths of size 7 ---\n",
      "Path [5][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp3tc[27504]@0: 0.0056 <- embed0@0: 0.012\n",
      "Path [5][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- embed0@0: 0.0077\n",
      "Path [5][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp5tc[8363]@0: 0.0055 <- embed0@0: 0.0045\n",
      "Path [5][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- mlp0tc[366]@0: 0.0073 <- embed0@0: 0.0042\n",
      "Path [5][4]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp0tc[40874]@0: 0.0069 <- embed0@0: 0.0026\n",
      "Path [5][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- mlp0tc[43064]@0: 0.0078 <- embed0@0: 0.0018\n",
      "Path [5][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[10560]@0: 0.00033\n",
      "Path [5][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[34573]@0: 0.00027\n",
      "Path [5][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[18665]@0: 0.00027\n",
      "Path [5][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027\n",
      "Path [5][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[21025]@0: 0.00026\n",
      "Path [5][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp1tc[7317]@0: 0.0059 <- embed0@0: 0.00025\n",
      "Path [5][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- mlp0tc[43064]@0: 0.0078 <- attn0[10]@0: 0.00023\n",
      "Path [5][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[6623]@0: 0.00022\n",
      "Path [5][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[42233]@0: 0.00021\n",
      "--- Paths of size 8 ---\n",
      "Path [6][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[18665]@0: 0.00027 <- embed0@0: 0.00062\n",
      "Path [6][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[10560]@0: 0.00033 <- embed0@0: 0.0005\n",
      "Path [6][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[34573]@0: 0.00027 <- embed0@0: 0.00042\n",
      "Path [6][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[21025]@0: 0.00026 <- embed0@0: 0.00042\n",
      "Path [6][4]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[6623]@0: 0.00022 <- embed0@0: 0.00035\n",
      "Path [6][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[42233]@0: 0.00021 <- embed0@0: 0.00033\n",
      "Path [6][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- embed0@0: 0.00019\n",
      "Path [6][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[40874]@0: 4.9e-05\n",
      "Path [6][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05\n",
      "Path [6][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[37518]@0: 3.8e-05\n",
      "Path [6][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[36957]@0: 3.1e-05\n",
      "Path [6][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[43205]@0: 3e-05\n",
      "Path [6][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[18665]@0: 0.00027 <- mlp0tc[43064]@0: 2.5e-05\n",
      "Path [6][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05\n",
      "Path [6][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[16727]@0: 2.1e-05\n",
      "--- Paths of size 9 ---\n",
      "Path [7][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- embed0@0: 4.3e-05\n",
      "Path [7][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[36957]@0: 3.1e-05 <- embed0@0: 3.2e-05\n",
      "Path [7][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[43205]@0: 3e-05 <- embed0@0: 2.3e-05\n",
      "Path [7][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[40874]@0: 4.9e-05 <- embed0@0: 1.9e-05\n",
      "Path [7][4]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[16727]@0: 2.1e-05 <- embed0@0: 6e-06\n",
      "Path [7][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[18665]@0: 0.00027 <- mlp0tc[43064]@0: 2.5e-05 <- embed0@0: 5.7e-06\n",
      "Path [7][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- embed0@0: 2e-06\n",
      "Path [7][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- mlp0tc[3062]@0: 1.4e-06\n",
      "Path [7][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[16727]@0: 1.3e-06\n",
      "Path [7][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[36957]@0: 3.1e-05 <- attn0[5]@0: 9.2e-07\n",
      "Path [7][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[40574]@0: 7.7e-07\n",
      "Path [7][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[26915]@0: 7.5e-07\n",
      "Path [7][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[18665]@0: 0.00027 <- mlp0tc[43064]@0: 2.5e-05 <- attn0[10]@0: 7.5e-07\n",
      "Path [7][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- attn0[5]@0: 7.3e-07\n",
      "Path [7][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[2959]@0: 7.2e-07\n",
      "--- Paths of size 10 ---\n",
      "Path [8][0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[26915]@0: 7.5e-07 <- embed0@0: 7.2e-07\n",
      "Path [8][1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- mlp0tc[3062]@0: 1.4e-06 <- embed0@0: 4.8e-07\n",
      "Path [8][2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[16727]@0: 1.3e-06 <- embed0@0: 3.7e-07\n",
      "Path [8][3]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[40574]@0: 7.7e-07 <- embed0@0: 3.2e-07\n",
      "Path [8][4]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[2959]@0: 7.2e-07 <- embed0@0: 7.8e-08\n",
      "Path [8][5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[16727]@0: 1.3e-06 <- attn0[9]@0: 2.7e-08\n",
      "Path [8][6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[16727]@0: 1.3e-06 <- attn0[3]@0: 2.4e-08\n",
      "Path [8][7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[16727]@0: 1.3e-06 <- attn0[4]@0: 2.1e-08\n",
      "Path [8][8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- mlp0tc[3062]@0: 1.4e-06 <- attn0[2]@0: 2e-08\n",
      "Path [8][9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[26915]@0: 7.5e-07 <- attn0[2]@0: 1.8e-08\n",
      "Path [8][10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- mlp0tc[3062]@0: 1.4e-06 <- attn0[7]@0: 1.5e-08\n",
      "Path [8][11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[40574]@0: 7.7e-07 <- attn0[5]@0: 1.1e-08\n",
      "Path [8][12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- mlp0tc[3062]@0: 1.4e-06 <- attn0[3]@0: 9.1e-09\n",
      "Path [8][13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[26915]@0: 7.5e-07 <- attn0[5]@0: 8.2e-09\n",
      "Path [8][14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[26915]@0: 7.5e-07 <- attn0[0]@0: 8.1e-09\n"
     ]
    }
   ],
   "source": [
    "print_all_paths(all_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "class FilterType(enum.Enum):\n",
    "    EQ = enum.auto()  # equals\n",
    "    NE = enum.auto()  # not equal to\n",
    "    GT = enum.auto()  # greater than\n",
    "    GE = enum.auto()  # greater than or equal to\n",
    "    LT = enum.auto()  # less than\n",
    "    LE = enum.auto()  # less than or equal to\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FeatureFilter:\n",
    "    # feature-level filters\n",
    "    layer: Optional[int] = field(\n",
    "        default=None, metadata={\"filter_level\": \"feature\"}\n",
    "    )\n",
    "    layer_filter_type: FilterType = FilterType.EQ\n",
    "    sublayer: Optional[int] = field(\n",
    "        default=None, metadata={\"filter_level\": \"feature\"}\n",
    "    )\n",
    "    sublayer_filter_type: FilterType = FilterType.EQ\n",
    "    token: Optional[int] = field(\n",
    "        default=None, metadata={\"filter_level\": \"feature\"}\n",
    "    )\n",
    "    token_filter_type: FilterType = FilterType.EQ\n",
    "\n",
    "    # filters on last component in component_path\n",
    "    component_type: Optional[ComponentType] = field(\n",
    "        default=None, metadata={\"filter_level\": \"component\"}\n",
    "    )\n",
    "    component_type_filter_type: FilterType = FilterType.EQ\n",
    "    attn_head: Optional[int] = field(\n",
    "        default=None, metadata={\"filter_level\": \"component\"}\n",
    "    )\n",
    "    attn_head_filter_type: FilterType = FilterType.EQ\n",
    "    feature_type: Optional[FeatureType] = field(\n",
    "        default=None, metadata={\"filter_level\": \"component\"}\n",
    "    )\n",
    "    feature_type_filter_type: FilterType = FilterType.EQ\n",
    "    feature_idx: Optional[int] = field(\n",
    "        default=None, metadata={\"filter_level\": \"component\"}\n",
    "    )\n",
    "    feature_idx_filter_type: FilterType = FilterType.EQ\n",
    "\n",
    "    def match(self, feature):\n",
    "        component = None\n",
    "\n",
    "        for field in dataclasses.fields(self):\n",
    "            name = field.name\n",
    "            val = self.__dict__[name]\n",
    "            if val is None:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                filter_level = field.metadata[\"filter_level\"]\n",
    "            except KeyError:\n",
    "                continue  # not a filter\n",
    "            if filter_level == \"feature\":\n",
    "                if val is not None:\n",
    "                    filter_type = self.__dict__[f\"{name}_filter_type\"]\n",
    "                    if (\n",
    "                        filter_type == FilterType.EQ\n",
    "                        and val != feature.__dict__[name]\n",
    "                    ):\n",
    "                        return False\n",
    "                    if (\n",
    "                        filter_type == FilterType.NE\n",
    "                        and val == feature.__dict__[name]\n",
    "                    ):\n",
    "                        return False\n",
    "                    if (\n",
    "                        filter_type == FilterType.GT\n",
    "                        and feature.__dict__[name] <= val\n",
    "                    ):\n",
    "                        return False\n",
    "                    if (\n",
    "                        filter_type == FilterType.GE\n",
    "                        and feature.__dict__[name] < val\n",
    "                    ):\n",
    "                        return False\n",
    "                    if (\n",
    "                        filter_type == FilterType.LT\n",
    "                        and feature.__dict__[name] >= val\n",
    "                    ):\n",
    "                        return False\n",
    "                    if (\n",
    "                        filter_type == FilterType.LE\n",
    "                        and feature.__dict__[name] > val\n",
    "                    ):\n",
    "                        return False\n",
    "            elif filter_level == \"component\":\n",
    "                if component is None:\n",
    "                    if len(feature.component_path) <= 0:\n",
    "                        return False\n",
    "                    component = feature.component_path[-1]\n",
    "                if val is not None:\n",
    "                    filter_type = self.__dict__[f\"{name}_filter_type\"]\n",
    "                    if (\n",
    "                        filter_type == FilterType.EQ\n",
    "                        and val != component.__dict__[name]\n",
    "                    ):\n",
    "                        return False\n",
    "                    if (\n",
    "                        filter_type == FilterType.NE\n",
    "                        and val == component.__dict__[name]\n",
    "                    ):\n",
    "                        return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter paths\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "def flatten_nested_list(x):\n",
    "    return list(functools.reduce(lambda a, b: a + b, x))\n",
    "\n",
    "\n",
    "def get_paths_via_filter(\n",
    "    all_paths, infix_path=None, not_infix_path=None, suffix_path=None\n",
    "):\n",
    "    retpaths = []\n",
    "    if type(all_paths[0][0]) is list:\n",
    "        path_list = flatten_nested_list(all_paths)\n",
    "    else:\n",
    "        path_list = all_paths\n",
    "    for path in path_list:\n",
    "        if not_infix_path is not None:\n",
    "            if len(path) < len(not_infix_path):\n",
    "                continue\n",
    "\n",
    "            match_started = False\n",
    "            path_good = True\n",
    "            i = 0\n",
    "            for j, cur_feature in enumerate(path):\n",
    "                cur_infix_filter = not_infix_path[i]\n",
    "\n",
    "                if cur_infix_filter.match(cur_feature):\n",
    "                    if not match_started:\n",
    "                        if len(path[j:]) < len(not_infix_path):\n",
    "                            break\n",
    "                        match_started = True\n",
    "                elif match_started:\n",
    "                    path_good = False\n",
    "                    break\n",
    "\n",
    "                if match_started:\n",
    "                    i = i + 1\n",
    "                    if i >= len(not_infix_path):\n",
    "                        break\n",
    "            if not (match_started and path_good):\n",
    "                retpaths.append(path)\n",
    "\n",
    "        if infix_path is not None:\n",
    "            if len(path) < len(infix_path):\n",
    "                continue\n",
    "\n",
    "            match_started = False\n",
    "            path_good = True\n",
    "            i = 0\n",
    "            for j, cur_feature in enumerate(path):\n",
    "                cur_infix_filter = infix_path[i]\n",
    "\n",
    "                if cur_infix_filter.match(cur_feature):\n",
    "                    if not match_started:\n",
    "                        if len(path[j:]) < len(infix_path):\n",
    "                            break\n",
    "                        match_started = True\n",
    "                elif match_started:\n",
    "                    path_good = False\n",
    "                    break\n",
    "\n",
    "                if match_started:\n",
    "                    i = i + 1\n",
    "                    if i >= len(infix_path):\n",
    "                        break\n",
    "            if match_started and path_good:\n",
    "                retpaths.append(path)\n",
    "\n",
    "        if suffix_path is not None:\n",
    "            if len(path) < len(suffix_path):\n",
    "                continue\n",
    "            path_good = True\n",
    "            for i in range(1, len(suffix_path) + 1):\n",
    "                cur_feature = path[-i]\n",
    "                cur_suffix_filter = suffix_path[-i]\n",
    "                if not cur_suffix_filter.match(cur_feature):\n",
    "                    path_good = False\n",
    "                    break\n",
    "            if path_good:\n",
    "                retpaths.append(path)\n",
    "    return retpaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92789f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path [0]: mlp10tc[46014]@0: 5.4 <- mlp9tc[37227]@0: 2.7 <- embed0@0: 2.1\n",
      "Path [1]: mlp10tc[46014]@0: 5.4 <- mlp9tc[43817]@0: 2.0 <- embed0@0: 1.9\n",
      "Path [2]: mlp10tc[46014]@0: 5.4 <- mlp9tc[1987]@0: 2.1 <- embed0@0: 1.5\n",
      "Path [3]: mlp10tc[46014]@0: 5.4 <- mlp8tc[41884]@0: 1.7 <- embed0@0: 1.5\n",
      "Path [4]: mlp10tc[46014]@0: 5.4 <- mlp8tc[7053]@0: 2.1 <- embed0@0: 1.4\n",
      "Path [5]: mlp10tc[46014]@0: 5.4 <- mlp9tc[31906]@0: 1.5 <- embed0@0: 1.2\n",
      "Path [6]: mlp10tc[46014]@0: 5.4 <- mlp9tc[188]@0: 2.3 <- embed0@0: 1.2\n",
      "Path [7]: mlp10tc[46014]@0: 5.4 <- mlp9tc[6684]@0: 1.6 <- embed0@0: 0.98\n",
      "Path [8]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp6tc[6360]@0: 1.0 <- embed0@0: 2.4\n",
      "Path [9]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp7tc[46190]@0: 1.3 <- embed0@0: 2.3\n",
      "Path [10]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[17621]@0: 0.83 <- embed0@0: 1.1\n",
      "Path [11]: mlp10tc[46014]@0: 5.4 <- mlp9tc[44224]@0: 2.5 <- mlp7tc[6843]@0: 0.84 <- embed0@0: 1.1\n",
      "Path [12]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[31058]@0: 1.1 <- embed0@0: 1.0\n",
      "Path [13]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- embed0@0: 0.98\n",
      "Path [14]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[36664]@0: 0.87 <- embed0@0: 0.49\n",
      "Path [15]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- embed0@0: 1.3\n",
      "Path [16]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp6tc[6360]@0: 1.0 <- mlp3tc[23198]@0: 0.21 <- embed0@0: 0.28\n",
      "Path [17]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp2tc[3893]@0: 0.17 <- embed0@0: 0.22\n",
      "Path [18]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[17621]@0: 0.83 <- mlp7tc[44596]@0: 0.15 <- embed0@0: 0.22\n",
      "Path [19]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp5tc[7438]@0: 0.21 <- embed0@0: 0.19\n",
      "Path [20]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp5tc[17135]@0: 0.16 <- embed0@0: 0.18\n",
      "Path [21]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- embed0@0: 0.29\n",
      "Path [22]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp2tc[33043]@0: 0.11 <- embed0@0: 0.18\n",
      "Path [23]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp3tc[23198]@0: 0.12 <- embed0@0: 0.16\n",
      "Path [24]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- embed0@0: 0.15\n",
      "Path [25]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- embed0@0: 0.13\n",
      "Path [26]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp3tc[46689]@0: 0.099 <- embed0@0: 0.079\n",
      "Path [27]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp0tc[40874]@0: 0.13 <- embed0@0: 0.049\n",
      "Path [28]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp0tc[16727]@0: 0.11 <- embed0@0: 0.03\n",
      "Path [29]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp3tc[27504]@0: 0.0056 <- embed0@0: 0.012\n",
      "Path [30]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- embed0@0: 0.0077\n",
      "Path [31]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp5tc[8363]@0: 0.0055 <- embed0@0: 0.0045\n",
      "Path [32]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- mlp0tc[366]@0: 0.0073 <- embed0@0: 0.0042\n",
      "Path [33]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp0tc[40874]@0: 0.0069 <- embed0@0: 0.0026\n",
      "Path [34]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp1tc[45268]@0: 0.1 <- mlp0tc[43064]@0: 0.0078 <- embed0@0: 0.0018\n",
      "Path [35]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp6tc[42390]@0: 0.13 <- mlp1tc[7317]@0: 0.0059 <- embed0@0: 0.00025\n",
      "Path [36]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[18665]@0: 0.00027 <- embed0@0: 0.00062\n",
      "Path [37]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[10560]@0: 0.00033 <- embed0@0: 0.0005\n",
      "Path [38]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[34573]@0: 0.00027 <- embed0@0: 0.00042\n",
      "Path [39]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[21025]@0: 0.00026 <- embed0@0: 0.00042\n",
      "Path [40]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[6623]@0: 0.00022 <- embed0@0: 0.00035\n",
      "Path [41]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[42233]@0: 0.00021 <- embed0@0: 0.00033\n",
      "Path [42]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- embed0@0: 0.00019\n",
      "Path [43]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- embed0@0: 4.3e-05\n",
      "Path [44]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[36957]@0: 3.1e-05 <- embed0@0: 3.2e-05\n",
      "Path [45]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[43205]@0: 3e-05 <- embed0@0: 2.3e-05\n",
      "Path [46]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[40874]@0: 4.9e-05 <- embed0@0: 1.9e-05\n",
      "Path [47]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp0tc[16727]@0: 2.1e-05 <- embed0@0: 6e-06\n",
      "Path [48]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp1tc[18665]@0: 0.00027 <- mlp0tc[43064]@0: 2.5e-05 <- embed0@0: 5.7e-06\n",
      "Path [49]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- embed0@0: 2e-06\n",
      "Path [50]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[26915]@0: 7.5e-07 <- embed0@0: 7.2e-07\n",
      "Path [51]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[7317]@0: 4.7e-05 <- mlp0tc[3062]@0: 1.4e-06 <- embed0@0: 4.8e-07\n",
      "Path [52]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[16727]@0: 1.3e-06 <- embed0@0: 3.7e-07\n",
      "Path [53]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[40574]@0: 7.7e-07 <- embed0@0: 3.2e-07\n",
      "Path [54]: mlp10tc[46014]@0: 5.4 <- mlp9tc[18226]@0: 1.9 <- mlp8tc[45226]@0: 0.96 <- mlp7tc[40475]@0: 0.14 <- mlp5tc[19138]@0: 0.14 <- mlp3tc[46604]@0: 0.0073 <- mlp2tc[4712]@0: 0.00027 <- mlp1tc[2320]@0: 2.4e-05 <- mlp0tc[2959]@0: 7.2e-07 <- embed0@0: 7.8e-08\n"
     ]
    }
   ],
   "source": [
    "# # ignore paths that go through MLP2 transcoder\n",
    "# filtered_paths = get_paths_via_filter(all_paths, not_infix_path=[\n",
    "#     FeatureFilter(\n",
    "#         layer=2, layer_filter_type=FilterType.EQ,\n",
    "#         feature_type=FeatureType.TRANSCODER\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# # ignore paths that end in last token\n",
    "# filtered_paths = get_paths_via_filter(filtered_paths, suffix_path=[\n",
    "#     FeatureFilter(token=9, token_filter_type=FilterType.NE)\n",
    "# ])\n",
    "\n",
    "# look at paths that end in layer 0\n",
    "filtered_paths = get_paths_via_filter(\n",
    "    all_paths,\n",
    "    suffix_path=[FeatureFilter(component_type=ComponentType.EMBED, layer=0)],\n",
    ")\n",
    "\n",
    "print_all_paths(filtered_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b2a44",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "We will see what each feature means. Since CLIP is an encoder model, we cannot use the same de-embedding method in the example. We will use the cosine similarity instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0dc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49408, 512])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.token_embedding.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a4a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 512])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual.proj.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250c06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39957, 512])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759a598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
      "  (patch_dropout): Identity()\n",
      "  (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (transformer): Transformer(\n",
      "    (resblocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.visual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the tuned lens\n",
    "import src.clip_tl\n",
    "\n",
    "lens_dir = \"/nfs/turbo/coe-chaijy/janeding/regrounding/clip_tl/outputs/5_percent_no_wandb/final_lens\"\n",
    "\n",
    "# load the lens\n",
    "lens = src.clip_tl.CLIPTunedLens.from_pretrained_model(lens_dir, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb09487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTunedLens(\n",
       "  (unembed): Unembed(\n",
       "    (model): CLIP(\n",
       "      (visual): VisionTransformer(\n",
       "        (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "        (patch_dropout): Identity()\n",
       "        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (transformer): Transformer(\n",
       "          (resblocks): ModuleList(\n",
       "            (0-11): 12 x ResidualAttentionBlock(\n",
       "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (ls_1): Identity()\n",
       "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Sequential(\n",
       "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (gelu): GELU(approximate='none')\n",
       "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (ls_2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (unembedding): Linear(in_features=49408, out_features=512, bias=False)\n",
       "    (projection): Linear(in_features=512, out_features=768, bias=False)\n",
       "  )\n",
       "  (layer_translators): ModuleList(\n",
       "    (0-11): 12 x Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378af58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTunedLens(\n",
       "  (unembed): Unembed(\n",
       "    (model): CLIP(\n",
       "      (visual): VisionTransformer(\n",
       "        (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "        (patch_dropout): Identity()\n",
       "        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (transformer): Transformer(\n",
       "          (resblocks): ModuleList(\n",
       "            (0-11): 12 x ResidualAttentionBlock(\n",
       "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (ls_1): Identity()\n",
       "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Sequential(\n",
       "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (gelu): GELU(approximate='none')\n",
       "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (ls_2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (unembedding): Linear(in_features=49408, out_features=512, bias=False)\n",
       "    (projection): Linear(in_features=512, out_features=768, bias=False)\n",
       "  )\n",
       "  (layer_translators): ModuleList(\n",
       "    (0-11): 12 x Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cef82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.2412e-01, -3.0766e-01, -9.6770e-01, -1.2275e+00,  7.2285e-01,\n",
       "         4.1162e-01, -1.9858e-01,  9.0384e-01, -4.4039e-01,  1.2508e-01,\n",
       "         3.4716e-01,  3.2294e-01, -2.3396e-02,  6.1813e-01, -2.8679e-01,\n",
       "        -8.1113e-01, -5.9759e-01, -1.1294e-01, -8.7585e-02, -3.7383e-01,\n",
       "         4.2546e-01, -6.2258e-01, -6.0247e-01,  6.0657e-01,  1.2804e-01,\n",
       "         3.6381e-01, -2.5822e-01,  2.4766e-01,  3.5882e-01, -1.1150e+00,\n",
       "        -5.1590e-01,  1.3532e+00,  3.0733e-01,  1.0090e-01,  1.0695e+00,\n",
       "        -5.2416e-01, -2.0310e-01,  1.0226e-01, -2.0105e-02, -7.0213e-01,\n",
       "         1.0978e+00,  2.9248e-01,  5.3526e-01,  4.7518e-01, -2.2894e-02,\n",
       "         1.5130e-01, -4.1909e-01, -5.0735e-02,  6.1323e-01,  1.0651e-01,\n",
       "         3.3296e-02, -3.6876e-01, -4.5924e-01, -1.1333e+00,  3.8579e-01,\n",
       "        -3.7678e-01, -4.8249e-01, -3.6191e-01, -4.2063e-01,  8.7485e-01,\n",
       "        -2.0670e-01,  1.6377e-01, -3.5684e-01,  2.6176e-01,  5.2383e-01,\n",
       "         5.7559e-02,  1.8655e-01,  3.9036e-02,  2.9768e-02,  4.1139e-01,\n",
       "         7.0629e-02, -1.4091e-01,  3.3287e-01,  5.0211e-01,  4.5679e-01,\n",
       "        -5.9740e-01, -5.4826e-02,  1.4510e+00,  3.2635e-01,  3.3265e-01,\n",
       "        -1.9364e-01,  5.2206e-01,  6.0795e-01,  1.1938e+00,  2.5758e-01,\n",
       "         6.9161e-01, -6.8243e-01,  4.4462e-01, -5.3246e-01,  3.4475e-01,\n",
       "        -7.5653e-01,  1.8707e-02, -5.4162e-01,  6.2711e-02,  1.9019e-01,\n",
       "         9.5597e-01,  3.0182e-01,  1.6027e-01,  7.0073e-01, -1.8619e-01,\n",
       "         7.0594e-01, -3.6872e-01,  1.6308e-01,  4.9719e-02,  6.8884e-02,\n",
       "         3.6343e-01,  9.3677e-01, -8.8531e-01,  8.4397e-01, -2.9324e-01,\n",
       "         5.5462e-01,  6.8761e-02,  7.4020e-02, -7.3190e-02,  2.3505e-02,\n",
       "        -6.4323e-02, -6.2671e-01,  8.3936e-01,  5.1156e-01, -4.1645e-01,\n",
       "         4.7489e-01, -8.8592e-02, -1.0834e-01,  6.2449e-01,  5.4172e-02,\n",
       "         2.3721e-01, -1.2491e-01, -8.2261e-01, -5.9302e-02,  2.6033e-01,\n",
       "         3.3937e-02, -6.4617e-01,  2.5210e-01, -1.8038e-01,  1.7479e-01,\n",
       "         8.2701e-03,  2.1794e-01,  3.5495e-01,  2.6282e-01, -7.1468e-01,\n",
       "         2.6786e-01, -3.0672e-01, -2.6650e-01, -1.2448e-01, -5.5216e-01,\n",
       "        -3.3373e-01, -5.6411e-01, -3.8215e-01, -4.1169e-01, -5.8555e-01,\n",
       "         6.8538e-01, -1.5013e-03, -3.8654e-01, -2.2082e-01,  9.7581e-01,\n",
       "         2.9141e-01,  3.3933e-01, -5.5243e-01,  5.8440e-01,  3.9903e-01,\n",
       "        -2.0660e-01, -3.3292e-01,  2.9343e-01,  3.6800e-01,  3.2088e-02,\n",
       "         6.2104e-01, -7.1578e-02,  5.6225e-01, -4.7027e-01,  1.2324e+00,\n",
       "        -3.7900e-01,  5.7647e-01, -1.2058e+00, -1.2434e+00, -1.4934e-01,\n",
       "         8.4725e-02, -2.4454e-01,  3.5547e-02,  6.4290e-01,  9.7923e-01,\n",
       "         5.5575e-01,  7.7004e-01, -7.6028e-01,  7.7529e-02, -7.8653e-01,\n",
       "         2.4776e-01, -2.0049e-01,  1.4913e-01,  2.9394e-01,  3.0205e-01,\n",
       "        -6.3966e-02,  5.0905e-02,  2.2025e-01, -5.5408e-01,  2.4803e-01,\n",
       "         1.1283e+00, -7.3350e-01, -1.1662e+00, -1.8549e-01, -4.7878e-01,\n",
       "         1.5138e+00,  1.3404e-01, -1.2218e-01,  2.1519e-01,  7.3570e-01,\n",
       "        -3.7607e-01,  8.5073e-01, -7.2826e-01, -2.7595e-01,  2.7250e-02,\n",
       "        -4.0854e-01,  3.9477e-01, -3.3142e-01,  5.2921e-01,  9.0645e-01,\n",
       "        -5.3911e-01,  1.2150e+00, -5.9047e-01,  2.9729e-01,  5.6357e-01,\n",
       "        -4.0100e-01,  2.0888e+00,  4.3795e-01, -4.8667e-01,  5.6499e-01,\n",
       "         6.8257e-01, -5.1652e-01, -2.6380e-01, -1.1194e+00,  6.4484e-01,\n",
       "         4.6378e-01,  5.8199e-01, -3.0751e-02, -1.9486e-01, -3.2202e-01,\n",
       "         9.9224e-01, -4.0325e-01, -4.4295e-01,  3.0155e-01, -5.5205e-01,\n",
       "        -3.9783e-01,  1.4510e-01,  2.4383e-01, -2.0418e-01, -1.0041e+00,\n",
       "         2.7684e-02, -5.6942e-02, -1.8220e-01,  3.0193e-01,  3.6065e-01,\n",
       "        -7.9624e-02, -4.4311e-01,  2.7265e-01,  8.8091e-01, -6.4353e-01,\n",
       "         4.0491e-01,  8.5082e-02, -2.2931e-02,  1.8962e-01, -1.0767e+00,\n",
       "        -1.7310e-02, -6.5338e-01, -3.5848e-02,  2.6389e-02, -6.7708e-01,\n",
       "        -7.2155e-01, -5.6280e-02,  4.2110e-01,  3.1616e-01,  3.4892e-01,\n",
       "        -6.9478e-01,  8.8348e-02,  4.0137e-01, -5.3326e-01, -5.7645e-01,\n",
       "         6.6416e-01,  7.3009e-03, -4.6335e-01,  8.0603e-01,  8.1733e-02,\n",
       "         7.0332e-01,  4.4216e-01,  8.1890e-01, -6.7118e-01,  1.6142e-01,\n",
       "         6.0833e-03,  2.1363e-01,  3.5007e-01,  2.5986e-01, -3.1452e-01,\n",
       "         4.4759e-01,  6.4174e-01,  4.9928e-01,  4.2140e-01, -5.3706e-01,\n",
       "        -2.4433e-01,  4.0454e-01, -6.2729e-01,  1.4747e-01, -7.5573e-02,\n",
       "        -1.0979e-01,  2.9685e-01,  1.0187e-01, -3.6949e-01, -9.4105e-01,\n",
       "         1.0153e+00,  9.7741e-01,  5.5950e-01, -1.3497e-01,  4.9610e-01,\n",
       "         5.4919e-01, -4.6583e-01, -3.8998e-01,  2.1935e-01, -2.7689e-01,\n",
       "        -5.7436e-01,  2.2614e-01,  3.5298e-01, -8.8682e-02, -6.9513e-01,\n",
       "        -3.7273e-01,  2.4008e-01,  2.8293e-01,  3.9098e-01, -3.1110e-01,\n",
       "         2.0585e-01, -1.5286e-01, -5.3546e-01, -1.7845e-01,  4.1464e-01,\n",
       "        -1.1205e+00,  4.1766e-01,  1.1467e-01,  5.0158e-02,  1.1115e-01,\n",
       "         5.6241e-02,  1.2734e+00, -5.9982e-01,  5.5581e-01, -1.7925e-01,\n",
       "         5.4776e-02,  1.5790e-01, -2.5303e-01, -5.6592e-01,  1.0613e+00,\n",
       "         5.4054e-01, -6.2979e-01,  1.8300e+00, -3.7721e-01,  3.8995e-01,\n",
       "         3.3572e-01,  8.0970e-01,  6.8522e-01,  7.4136e-01, -6.0107e-01,\n",
       "        -4.5685e-01,  8.6572e-01, -1.1195e+00, -6.3508e-01,  5.6597e-01,\n",
       "         1.1044e+00,  2.2442e-02, -1.2063e-01, -6.5909e-01,  3.8535e-01,\n",
       "         3.2658e-01, -8.3802e-01,  5.4872e-01,  6.1148e-02,  1.3550e-01,\n",
       "         4.6090e-01,  2.4375e-01, -1.3396e-01,  4.0752e-01, -6.7375e-01,\n",
       "        -4.9782e-01, -7.5568e-02,  2.7052e-01, -6.0175e-01, -2.9011e-02,\n",
       "        -4.0176e-01, -2.6219e-01, -8.4684e-01, -7.8403e-01,  8.7553e-01,\n",
       "         1.6823e-01,  5.3990e-01,  5.6684e-01, -1.4216e+00, -6.0221e-01,\n",
       "         2.5812e-01, -1.4804e-01, -5.6172e-02, -8.9338e-02,  1.2676e-01,\n",
       "         8.1921e-01, -7.2720e-01, -9.5283e-01,  1.6874e-02,  5.5843e-02,\n",
       "         7.5920e-01,  1.0177e+00, -7.0920e-01,  3.4647e-01, -2.7767e-01,\n",
       "         4.7595e-01,  2.9408e-01,  1.2124e-01, -5.3175e-01,  4.2636e-02,\n",
       "        -4.7563e-01, -1.7505e-01, -8.2905e-01, -8.1176e-01, -3.3811e-01,\n",
       "         1.1989e+00,  2.0424e-01, -6.1983e-01,  1.8546e-01, -2.3161e-01,\n",
       "         7.2936e-01, -7.9761e-01,  1.3379e-01, -1.1384e+00,  4.8457e-01,\n",
       "         1.4676e-02, -6.8145e-01, -3.1739e-01, -2.9597e-02, -2.9422e-01,\n",
       "        -1.6091e+00,  1.6867e+00,  1.4381e-02, -2.6497e-01,  7.1881e-01,\n",
       "        -2.5084e-01,  1.6743e-03, -1.5006e-01,  3.3625e-01,  1.6306e-01,\n",
       "         7.5284e-01, -2.7030e-01,  3.0360e-01, -5.2477e-01, -1.1650e+00,\n",
       "         6.4154e-01, -5.0855e-01,  6.0459e-01, -1.0259e-01,  1.3001e-01,\n",
       "        -5.4242e-01, -2.2463e-01, -9.8167e-01, -1.5510e-01,  1.8474e+00,\n",
       "        -9.3201e-02,  7.0292e-02,  7.7182e-02,  7.3091e-01,  8.3718e-01,\n",
       "         1.1773e+00,  4.6951e-01,  2.7031e-01,  8.0790e-01, -1.0645e+00,\n",
       "         4.7319e-01, -1.3085e-01, -3.3126e-01,  6.3506e-02,  1.7825e-01,\n",
       "        -4.7373e-01, -2.2768e-02, -8.8679e-02,  2.7253e-01,  6.2630e-01,\n",
       "         4.0713e-01, -1.6971e-01, -5.3370e-02, -4.0978e-01,  7.6632e-01,\n",
       "        -1.7243e-01, -6.6321e-02, -4.7186e-01,  2.0024e-01,  5.0945e-01,\n",
       "        -1.1288e-02, -1.0577e+00,  4.1904e-01,  6.6882e-01,  5.5254e-01,\n",
       "         4.2734e-01,  9.2288e-02,  9.0598e-01, -4.7255e-01,  4.1535e-01,\n",
       "        -3.4927e-01, -7.9023e-03, -3.3236e-01,  1.2277e-01, -7.2939e-01,\n",
       "         5.8650e-01, -8.3151e-01,  4.2914e-01,  1.0704e-01,  4.6672e-01,\n",
       "         2.0729e-01,  1.0189e+00,  2.3445e-01,  2.6304e-01, -8.4224e-01,\n",
       "         3.8179e-01, -5.0277e-01], device='cuda:0')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.unembed.project_feature(all_paths[0][0][-1].vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deembeddings_for_feature_vector(\n",
    "    text_embeddings, lens, feature_vector, k=5\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        # pulledback_feature = model.W_E @ feature_vector.vector\n",
    "        projected_decoder_vectors = lens.unembed.project_feature(\n",
    "            feature_vector.vector\n",
    "        )\n",
    "        similarity = text_embeddings @ projected_decoder_vectors.T\n",
    "        top_k_scores, top_k_indices = torch.topk(similarity, k=k)\n",
    "        top_k_words = [labels[i] for i in top_k_indices]\n",
    "\n",
    "        # for i in range(k):\n",
    "        #     print(f\"{i+1}. label: {top_k_words[i]:<20} | prob: {top_k_scores[i].item():.4f}\")\n",
    "\n",
    "    if k == 1:\n",
    "        return top_k_words[0], top_k_scores[0].item()\n",
    "\n",
    "    return top_k_words, top_k_scores.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59bfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['acetaminophen', 'backbone', 'endorsement', 'ad', 'mammogram'],\n",
       " [1.2243785858154297,\n",
       "  1.165635585784912,\n",
       "  1.1536622047424316,\n",
       "  1.1380841732025146,\n",
       "  1.1339811086654663])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_deembeddings_for_feature_vector(\n",
    "    text_features, lens, all_paths[1][1][-1], k=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deembeddings_for_path(text_embeddings, lens, path, k=1) -> str:\n",
    "    YELLOW = \"\\033[93m\"  # yellow\n",
    "    RESET = \"\\033[0m\"  # reset color\n",
    "\n",
    "    result_parts = []\n",
    "    for feature in path:\n",
    "        try:\n",
    "            feature_str = feature.__str__()\n",
    "        except TypeError:\n",
    "            feature_str = str(feature)\n",
    "\n",
    "        words, score = get_deembeddings_for_feature_vector(\n",
    "            text_embeddings, lens, feature, k\n",
    "        )\n",
    "        # use yellow to highlight word\n",
    "        if type(words) == str:\n",
    "            highlighted_deembedding = f\"{YELLOW}{words}{RESET}\"\n",
    "        else:\n",
    "            highlighted_deembedding = f'{YELLOW}{\", \".join(words)}{RESET}'\n",
    "        result_parts.append(f\"{feature_str}({highlighted_deembedding})\")\n",
    "\n",
    "    results = \"  \".join(result_parts)\n",
    "    # print(results)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deembeddings_for_all_paths(\n",
    "    text_embeddings, lens, paths, k=1\n",
    ") -> list[str]:\n",
    "    if paths == []:\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for path in paths:\n",
    "        result = get_deembeddings_for_path(text_embeddings, lens, path, k)\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_deembeddings_for_all_paths(text_embeddings, lens, paths, k=1):\n",
    "    YELLOW = \"\\033[93m\"  # yellow\n",
    "    RESET = \"\\033[0m\"  # reset color\n",
    "    results = get_deembeddings_for_all_paths(text_embeddings, lens, paths, k)\n",
    "    if results:\n",
    "        print(f\"--- Paths of size {len(paths[0])} ---\")\n",
    "        for result in results:\n",
    "            print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    path_group = get_deembeddings_for_all_paths(\n",
    "        text_features, lens, all_paths[i], k=5\n",
    "    )\n",
    "    results.append(path_group)\n",
    "\n",
    "import datetime\n",
    "\n",
    "time_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "with open(os.path.join(log_dir, f\"results_{time_str}.log\"), \"a\") as f:\n",
    "    f.write(f\"Image: {img_path}\\n\")\n",
    "    f.write(f\"Label: {gt_label}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    for path_group in results:\n",
    "        for path in path_group:\n",
    "            f.write(path)\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b69ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paths of size 3 ---\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[37227]@0: 2.7(\u001b[93mhater, freckly, freckled, discolorations, similarity\u001b[0m)  mlp9tc[37227]embed0@0: 2.1(\u001b[93mhater, freckly, freckled, discolorations, similarity\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[43817]@0: 2.0(\u001b[93macetaminophen, backbone, endorsement, ad, mammogram\u001b[0m)  mlp9tc[43817]embed0@0: 1.9(\u001b[93macetaminophen, backbone, endorsement, ad, mammogram\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[1987]@0: 2.1(\u001b[93mwraparound, unscrambling, riboflavin, acceleration, move around\u001b[0m)  mlp9tc[1987]embed0@0: 1.5(\u001b[93mwraparound, unscrambling, riboflavin, acceleration, move around\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[41884]@0: 1.7(\u001b[93mundeniable, undeserved, undecided, incomparable, undeniably\u001b[0m)  mlp8tc[41884]embed0@0: 1.5(\u001b[93mundeniable, undeserved, undecided, incomparable, undeniably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[7053]@0: 2.1(\u001b[93mfranchise, catalog, workbook, certificate, sign on\u001b[0m)  mlp8tc[7053]embed0@0: 1.4(\u001b[93mfranchise, catalog, workbook, certificate, sign on\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[31906]@0: 1.5(\u001b[93mreaper, garter, treetop, wedging, lineman\u001b[0m)  mlp9tc[31906]embed0@0: 1.2(\u001b[93mreaper, garter, treetop, wedging, lineman\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[188]@0: 2.3(\u001b[93mwraparound, semitransparent, stemware, tier, slighting\u001b[0m)  mlp9tc[188]embed0@0: 1.2(\u001b[93mwraparound, semitransparent, stemware, tier, slighting\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[6684]@0: 1.6(\u001b[93mprintable, recipe, anagrams, sweetshop, internationalize\u001b[0m)  mlp9tc[6684]embed0@0: 0.98(\u001b[93mprintable, recipe, anagrams, sweetshop, internationalize\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp6tc[6360]@0: 1.0(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)  mlp6tc[6360]embed0@0: 2.4(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp7tc[46190]@0: 1.3(\u001b[93mfronted, threefold, emphatically, malarkey, wraparound\u001b[0m)  mlp7tc[46190]embed0@0: 2.3(\u001b[93mfronted, threefold, emphatically, malarkey, wraparound\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[17621]@0: 0.83(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)  mlp8tc[17621]embed0@0: 1.1(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[44224]@0: 2.5(\u001b[93mwraparound, webcast, cowardice, vest, clumpy\u001b[0m)  mlp7tc[6843]@0: 0.84(\u001b[93mcompartmentalization, compartmentalize, unassumingly, printable, worksheet\u001b[0m)  mlp7tc[6843]embed0@0: 1.1(\u001b[93mcompartmentalization, compartmentalize, unassumingly, printable, worksheet\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[31058]@0: 1.1(\u001b[93mindulgently, appoint, sepia, rest, teaser\u001b[0m)  mlp8tc[31058]embed0@0: 1.0(\u001b[93mindulgently, appoint, sepia, rest, teaser\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp8tc[45226]embed0@0: 0.98(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[36664]@0: 0.87(\u001b[93mwindshield wiper, hubcap, bow out, blue chip, periscope\u001b[0m)  mlp8tc[36664]embed0@0: 0.49(\u001b[93mwindshield wiper, hubcap, bow out, blue chip, periscope\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp7tc[40475]embed0@0: 1.3(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp6tc[6360]@0: 1.0(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)  mlp3tc[23198]@0: 0.21(\u001b[93muncondensed, reiterated, full, unissued, printable\u001b[0m)  mlp3tc[23198]embed0@0: 0.28(\u001b[93muncondensed, reiterated, full, unissued, printable\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp2tc[3893]@0: 0.17(\u001b[93mfoursome, wraparound, triple, tier, succinct\u001b[0m)  mlp2tc[3893]embed0@0: 0.22(\u001b[93mfoursome, wraparound, triple, tier, succinct\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[17621]@0: 0.83(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)  mlp7tc[44596]@0: 0.15(\u001b[93mreiterated, inconvertibly, leechlike, lavishing, convertibility\u001b[0m)  mlp7tc[44596]embed0@0: 0.22(\u001b[93mreiterated, inconvertibly, leechlike, lavishing, convertibility\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp5tc[7438]@0: 0.21(\u001b[93munblocked, share, unnoticeable, factsheet, gunmetal\u001b[0m)  mlp5tc[7438]embed0@0: 0.19(\u001b[93munblocked, share, unnoticeable, factsheet, gunmetal\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp5tc[17135]@0: 0.16(\u001b[93mimpressive, channeled, feminine, decameter, neatly\u001b[0m)  mlp5tc[17135]embed0@0: 0.18(\u001b[93mimpressive, channeled, feminine, decameter, neatly\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp6tc[42390]@0: 0.13(\u001b[93minformatively, situated, commenter, behalf, thumbnail\u001b[0m)  mlp6tc[42390]embed0@0: 0.29(\u001b[93minformatively, situated, commenter, behalf, thumbnail\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp2tc[33043]@0: 0.11(\u001b[93mcustomized, authentic, enjoyable, depersonalize, genuine\u001b[0m)  mlp2tc[33043]embed0@0: 0.18(\u001b[93mcustomized, authentic, enjoyable, depersonalize, genuine\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp3tc[23198]@0: 0.12(\u001b[93mreiterated, printable, full, wraparound, uncondensed\u001b[0m)  mlp3tc[23198]embed0@0: 0.16(\u001b[93mreiterated, printable, full, wraparound, uncondensed\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp1tc[45268]@0: 0.1(\u001b[93minset, subordinately, cherishment, subordinating, cherishingly\u001b[0m)  mlp1tc[45268]embed0@0: 0.15(\u001b[93minset, subordinately, cherishment, subordinating, cherishingly\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp5tc[19138]embed0@0: 0.13(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp3tc[46689]@0: 0.099(\u001b[93mgarnished, pair, fronted, adversely, suckling\u001b[0m)  mlp3tc[46689]embed0@0: 0.079(\u001b[93mgarnished, pair, fronted, adversely, suckling\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp0tc[40874]@0: 0.13(\u001b[93mclipart, supremely, mitt, item, printable\u001b[0m)  mlp0tc[40874]embed0@0: 0.049(\u001b[93mclipart, supremely, mitt, item, printable\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp0tc[16727]@0: 0.11(\u001b[93mtracing, monochromatically, printable, teaming, tripod\u001b[0m)  mlp0tc[16727]embed0@0: 0.03(\u001b[93mtracing, monochromatically, printable, teaming, tripod\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp6tc[42390]@0: 0.13(\u001b[93minformatively, situated, commenter, behalf, thumbnail\u001b[0m)  mlp3tc[27504]@0: 0.0056(\u001b[93mwraparound, printable, fronted, featured, favorably\u001b[0m)  mlp3tc[27504]embed0@0: 0.012(\u001b[93mwraparound, printable, fronted, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp3tc[46604]embed0@0: 0.0077(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp6tc[42390]@0: 0.13(\u001b[93minformatively, situated, commenter, behalf, thumbnail\u001b[0m)  mlp5tc[8363]@0: 0.0055(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp5tc[8363]embed0@0: 0.0045(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp1tc[45268]@0: 0.1(\u001b[93minset, subordinately, cherishment, subordinating, cherishingly\u001b[0m)  mlp0tc[366]@0: 0.0073(\u001b[93mfronted, full, wraparound, front, printable\u001b[0m)  mlp0tc[366]embed0@0: 0.0042(\u001b[93mfronted, full, wraparound, front, printable\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp6tc[42390]@0: 0.13(\u001b[93minformatively, situated, commenter, behalf, thumbnail\u001b[0m)  mlp0tc[40874]@0: 0.0069(\u001b[93mwraparound, printable, fronted, revised, favorably\u001b[0m)  mlp0tc[40874]embed0@0: 0.0026(\u001b[93mwraparound, printable, fronted, revised, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp1tc[45268]@0: 0.1(\u001b[93minset, subordinately, cherishment, subordinating, cherishingly\u001b[0m)  mlp0tc[43064]@0: 0.0078(\u001b[93mfronted, wraparound, printable, favorably, revised\u001b[0m)  mlp0tc[43064]embed0@0: 0.0018(\u001b[93mfronted, wraparound, printable, favorably, revised\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp6tc[42390]@0: 0.13(\u001b[93minformatively, situated, commenter, behalf, thumbnail\u001b[0m)  mlp1tc[7317]@0: 0.0059(\u001b[93mwraparound, fronted, featured, printable, favorably\u001b[0m)  mlp1tc[7317]embed0@0: 0.00025(\u001b[93mwraparound, fronted, featured, printable, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp1tc[18665]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[18665]embed0@0: 0.00062(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp1tc[10560]@0: 0.00033(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp1tc[10560]embed0@0: 0.0005(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp1tc[34573]@0: 0.00027(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp1tc[34573]embed0@0: 0.00042(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp1tc[21025]@0: 0.00026(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp1tc[21025]embed0@0: 0.00042(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp1tc[6623]@0: 0.00022(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp1tc[6623]embed0@0: 0.00035(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp1tc[42233]@0: 0.00021(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[42233]embed0@0: 0.00033(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp2tc[4712]embed0@0: 0.00019(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[2320]@0: 2.4e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp1tc[2320]embed0@0: 4.3e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp0tc[36957]@0: 3.1e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[36957]embed0@0: 3.2e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp0tc[43205]@0: 3e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[43205]embed0@0: 2.3e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp0tc[40874]@0: 4.9e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[40874]embed0@0: 1.9e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp0tc[16727]@0: 2.1e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[16727]embed0@0: 6e-06(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp1tc[18665]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp0tc[43064]@0: 2.5e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[43064]embed0@0: 5.7e-06(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[7317]@0: 4.7e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp1tc[7317]embed0@0: 2e-06(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[2320]@0: 2.4e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[26915]@0: 7.5e-07(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[26915]embed0@0: 7.2e-07(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[7317]@0: 4.7e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[3062]@0: 1.4e-06(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[3062]embed0@0: 4.8e-07(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[2320]@0: 2.4e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[16727]@0: 1.3e-06(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[16727]embed0@0: 3.7e-07(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[2320]@0: 2.4e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[40574]@0: 7.7e-07(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[40574]embed0@0: 3.2e-07(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)  mlp3tc[46604]@0: 0.0073(\u001b[93mwraparound, printable, fronted, foursome, revised\u001b[0m)  mlp2tc[4712]@0: 0.00027(\u001b[93mwraparound, fronted, printable, favorably, featured\u001b[0m)  mlp1tc[2320]@0: 2.4e-05(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[2959]@0: 7.2e-07(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)  mlp0tc[2959]embed0@0: 7.8e-08(\u001b[93mwraparound, fronted, printable, featured, favorably\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "print_deembeddings_for_all_paths(text_features, lens, filtered_paths, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paths of size 2 ---\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[37227]@0: 2.7(\u001b[93mhater, freckly, freckled, discolorations, similarity\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[3300]@0: 2.7(\u001b[93mfingering, devotedly, yellowy, red, pink\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[44224]@0: 2.5(\u001b[93mwraparound, webcast, cowardice, vest, clumpy\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[188]@0: 2.3(\u001b[93mwraparound, semitransparent, stemware, tier, slighting\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[7053]@0: 2.1(\u001b[93mfranchise, catalog, workbook, certificate, sign on\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[1987]@0: 2.1(\u001b[93mwraparound, unscrambling, riboflavin, acceleration, move around\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[43817]@0: 2.0(\u001b[93macetaminophen, backbone, endorsement, ad, mammogram\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[41884]@0: 1.7(\u001b[93mundeniable, undeserved, undecided, incomparable, undeniably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[42258]@0: 1.7(\u001b[93maristocratically, toned, freehandedly, toneless, proportionately\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[6684]@0: 1.6(\u001b[93mprintable, recipe, anagrams, sweetshop, internationalize\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[13869]@0: 1.6(\u001b[93mcocking, crasher, halftone, facedown, gashes\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[21658]@0: 1.5(\u001b[93mdolt, lid, dud, put, dilate\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[31906]@0: 1.5(\u001b[93mreaper, garter, treetop, wedging, lineman\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[6886]@0: 1.5(\u001b[93mincurability, hereditarily, adversely, terabyte, datasheet\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "print_deembeddings_for_all_paths(text_features, lens, all_paths[0], k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b70b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paths of size 3 ---\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[37227]@0: 2.7(\u001b[93mhater, freckly, freckled, discolorations, similarity\u001b[0m)  mlp9tc[37227]embed0@0: 2.1(\u001b[93mhater, freckly, freckled, discolorations, similarity\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[43817]@0: 2.0(\u001b[93macetaminophen, backbone, endorsement, ad, mammogram\u001b[0m)  mlp9tc[43817]embed0@0: 1.9(\u001b[93macetaminophen, backbone, endorsement, ad, mammogram\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[1987]@0: 2.1(\u001b[93mwraparound, unscrambling, riboflavin, acceleration, move around\u001b[0m)  mlp9tc[1987]embed0@0: 1.5(\u001b[93mwraparound, unscrambling, riboflavin, acceleration, move around\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[41884]@0: 1.7(\u001b[93mundeniable, undeserved, undecided, incomparable, undeniably\u001b[0m)  mlp8tc[41884]embed0@0: 1.5(\u001b[93mundeniable, undeserved, undecided, incomparable, undeniably\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp8tc[7053]@0: 2.1(\u001b[93mfranchise, catalog, workbook, certificate, sign on\u001b[0m)  mlp8tc[7053]embed0@0: 1.4(\u001b[93mfranchise, catalog, workbook, certificate, sign on\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp7tc[46190]@0: 1.3(\u001b[93mfronted, threefold, emphatically, malarkey, wraparound\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[31906]@0: 1.5(\u001b[93mreaper, garter, treetop, wedging, lineman\u001b[0m)  mlp9tc[31906]embed0@0: 1.2(\u001b[93mreaper, garter, treetop, wedging, lineman\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[188]@0: 2.3(\u001b[93mwraparound, semitransparent, stemware, tier, slighting\u001b[0m)  mlp9tc[188]embed0@0: 1.2(\u001b[93mwraparound, semitransparent, stemware, tier, slighting\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[31058]@0: 1.1(\u001b[93mindulgently, appoint, sepia, rest, teaser\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp6tc[6360]@0: 1.0(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[6684]@0: 1.6(\u001b[93mprintable, recipe, anagrams, sweetshop, internationalize\u001b[0m)  mlp9tc[6684]embed0@0: 0.98(\u001b[93mprintable, recipe, anagrams, sweetshop, internationalize\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[36664]@0: 0.87(\u001b[93mwindshield wiper, hubcap, bow out, blue chip, periscope\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[44224]@0: 2.5(\u001b[93mwraparound, webcast, cowardice, vest, clumpy\u001b[0m)  mlp7tc[6843]@0: 0.84(\u001b[93mcompartmentalization, compartmentalize, unassumingly, printable, worksheet\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[17621]@0: 0.83(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "print_deembeddings_for_all_paths(text_features, lens, all_paths[1], k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2f971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paths of size 4 ---\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp6tc[6360]@0: 1.0(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)  mlp6tc[6360]embed0@0: 2.4(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp7tc[46190]@0: 1.3(\u001b[93mfronted, threefold, emphatically, malarkey, wraparound\u001b[0m)  mlp7tc[46190]embed0@0: 2.3(\u001b[93mfronted, threefold, emphatically, malarkey, wraparound\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[17621]@0: 0.83(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)  mlp8tc[17621]embed0@0: 1.1(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[44224]@0: 2.5(\u001b[93mwraparound, webcast, cowardice, vest, clumpy\u001b[0m)  mlp7tc[6843]@0: 0.84(\u001b[93mcompartmentalization, compartmentalize, unassumingly, printable, worksheet\u001b[0m)  mlp7tc[6843]embed0@0: 1.1(\u001b[93mcompartmentalization, compartmentalize, unassumingly, printable, worksheet\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[31058]@0: 1.1(\u001b[93mindulgently, appoint, sepia, rest, teaser\u001b[0m)  mlp8tc[31058]embed0@0: 1.0(\u001b[93mindulgently, appoint, sepia, rest, teaser\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp8tc[45226]embed0@0: 0.98(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[36664]@0: 0.87(\u001b[93mwindshield wiper, hubcap, bow out, blue chip, periscope\u001b[0m)  mlp8tc[36664]embed0@0: 0.49(\u001b[93mwindshield wiper, hubcap, bow out, blue chip, periscope\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp5tc[7438]@0: 0.21(\u001b[93munblocked, share, unnoticeable, factsheet, gunmetal\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp6tc[6360]@0: 1.0(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)  mlp3tc[23198]@0: 0.21(\u001b[93muncondensed, reiterated, full, unissued, printable\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp6tc[6360]@0: 1.0(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)  mlp1tc[7317]@0: 0.2(\u001b[93mgunmetal, pouch, cased, banding, inset\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp2tc[3893]@0: 0.17(\u001b[93mfoursome, wraparound, triple, tier, succinct\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp5tc[17135]@0: 0.16(\u001b[93mimpressive, channeled, feminine, decameter, neatly\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[17621]@0: 0.83(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)  mlp7tc[44596]@0: 0.15(\u001b[93mreiterated, inconvertibly, leechlike, lavishing, convertibility\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp1tc[7317]@0: 0.14(\u001b[93mgunmetal, pouch, inset, cased, banding\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "print_deembeddings_for_all_paths(text_features, lens, all_paths[2], k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af0921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paths of size 5 ---\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp7tc[40475]embed0@0: 1.3(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp6tc[6360]@0: 1.0(\u001b[93mbusiness card, commenter, slogan, graphics, franchise\u001b[0m)  mlp3tc[23198]@0: 0.21(\u001b[93muncondensed, reiterated, full, unissued, printable\u001b[0m)  mlp3tc[23198]embed0@0: 0.28(\u001b[93muncondensed, reiterated, full, unissued, printable\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp2tc[3893]@0: 0.17(\u001b[93mfoursome, wraparound, triple, tier, succinct\u001b[0m)  mlp2tc[3893]embed0@0: 0.22(\u001b[93mfoursome, wraparound, triple, tier, succinct\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[17621]@0: 0.83(\u001b[93mrechargeable, home appliance, best seller, appliance, slogan\u001b[0m)  mlp7tc[44596]@0: 0.15(\u001b[93mreiterated, inconvertibly, leechlike, lavishing, convertibility\u001b[0m)  mlp7tc[44596]embed0@0: 0.22(\u001b[93mreiterated, inconvertibly, leechlike, lavishing, convertibility\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp5tc[7438]@0: 0.21(\u001b[93munblocked, share, unnoticeable, factsheet, gunmetal\u001b[0m)  mlp5tc[7438]embed0@0: 0.19(\u001b[93munblocked, share, unnoticeable, factsheet, gunmetal\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp5tc[17135]@0: 0.16(\u001b[93mimpressive, channeled, feminine, decameter, neatly\u001b[0m)  mlp5tc[17135]embed0@0: 0.18(\u001b[93mimpressive, channeled, feminine, decameter, neatly\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp5tc[19138]@0: 0.14(\u001b[93mmoronic, parka, whiteout, holograph, fogged\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp6tc[42390]@0: 0.13(\u001b[93minformatively, situated, commenter, behalf, thumbnail\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp0tc[40874]@0: 0.13(\u001b[93mclipart, supremely, mitt, item, printable\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp3tc[23198]@0: 0.12(\u001b[93mreiterated, printable, full, wraparound, uncondensed\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp0tc[16727]@0: 0.11(\u001b[93mtracing, monochromatically, printable, teaming, tripod\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp2tc[33043]@0: 0.11(\u001b[93mcustomized, authentic, enjoyable, depersonalize, genuine\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp7tc[40475]attn0[5]@0: 0.11(\u001b[93mbest selling, showy, speciality, sequentially, ecard\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp1tc[45268]@0: 0.1(\u001b[93minset, subordinately, cherishment, subordinating, cherishingly\u001b[0m)\n",
      "mlp10tc[46014]@0: 5.4(\u001b[93mlaboratory, biochemist, microanalysis, scientist, chemist\u001b[0m)  mlp9tc[18226]@0: 1.9(\u001b[93mthwarter, colorfulness, waver, crasher, tweaker\u001b[0m)  mlp8tc[45226]@0: 0.96(\u001b[93mautomobile, coupe, banner, vehicle, closeup\u001b[0m)  mlp7tc[40475]@0: 0.14(\u001b[93mthumbnail, threw, tutor, inner, inhibitive\u001b[0m)  mlp3tc[46689]@0: 0.099(\u001b[93mgarnished, pair, fronted, adversely, suckling\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "print_deembeddings_for_all_paths(text_features, lens, all_paths[3], k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deembeddings_for_transcoder_feature(\n",
    "    model, transcoder, feature_idx, attn_head=None, attn_layer=0, k=7\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        if attn_head is not None:\n",
    "            pulledback_feature = (\n",
    "                model.W_E\n",
    "                @ model.OV.AB[attn_layer, attn_head]\n",
    "                @ transcoder.W_enc[:, feature_idx]\n",
    "            )\n",
    "        else:\n",
    "            pulledback_feature = model.W_E @ transcoder.W_enc[:, feature_idx]\n",
    "        if k == 0:\n",
    "            return to_numpy(pulledback_feature)\n",
    "        else:\n",
    "            most_pos = torch.topk(pulledback_feature, k=k)\n",
    "            most_neg = torch.topk(-pulledback_feature, k=k)\n",
    "\n",
    "            top_vals = to_numpy(most_pos.values)\n",
    "            top_idxs = to_numpy(most_pos.indices)\n",
    "            top_tokens = open_clip.decode(most_pos.indices)\n",
    "\n",
    "            bot_vals = to_numpy(-most_neg.values)\n",
    "            bot_idxs = to_numpy(most_neg.indices)\n",
    "            bot_tokens = open_clip.decode(most_neg.indices)\n",
    "\n",
    "            return to_numpy(pulledback_feature), zip(\n",
    "                top_vals, top_tokens, bot_vals, bot_tokens\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b0218",
   "metadata": {},
   "source": [
    "# Test MAS\n",
    "We will test the max activated samples from the ImageNet Val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4a656",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in /nfs/turbo/coe-chaijy/janeding/regrounding/imagenet_val.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Put your imagenet path here. You can download ImageNet from kaggle.\u001b[39;00m\n\u001b[32m     32\u001b[39m imagenet_validation_path = \u001b[33m'\u001b[39m\u001b[33m/nfs/turbo/coe-chaijy/janeding/regrounding/imagenet_val\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m subset_dataloader, subset_dataset, viz_data = \u001b[43mload_imagenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagenet_validation_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mload_imagenet\u001b[39m\u001b[34m(imagenet_validation_path)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load dataset with CLIP transform\u001b[39;00m\n\u001b[32m     11\u001b[39m data_transforms = get_clip_val_transforms()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m val_data = \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagenet_validation_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# We'll also load a version of the dataset without the CLIP transform so that we can visualize it beautifully\u001b[39;00m\n\u001b[32m     15\u001b[39m viz_transforms = torchvision.transforms.Compose(\n\u001b[32m     16\u001b[39m                 [\n\u001b[32m     17\u001b[39m                     torchvision.transforms.Resize((\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)),\n\u001b[32m     18\u001b[39m                     torchvision.transforms.ToTensor(),\n\u001b[32m     19\u001b[39m                 ]\n\u001b[32m     20\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prisma/lib/python3.13/site-packages/torchvision/datasets/folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prisma/lib/python3.13/site-packages/torchvision/datasets/folder.py:149\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    140\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     classes, class_to_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     samples = \u001b[38;5;28mself\u001b[39m.make_dataset(\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.root,\n\u001b[32m    152\u001b[39m         class_to_idx=class_to_idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         allow_empty=allow_empty,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.loader = loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prisma/lib/python3.13/site-packages/torchvision/datasets/folder.py:234\u001b[39m, in \u001b[36mDatasetFolder.find_classes\u001b[39m\u001b[34m(self, directory)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m        directory/\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/prisma/lib/python3.13/site-packages/torchvision/datasets/folder.py:43\u001b[39m, in \u001b[36mfind_classes\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     41\u001b[39m classes = \u001b[38;5;28msorted\u001b[39m(entry.name \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os.scandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry.is_dir())\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m class_to_idx = {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Couldn't find any class folder in /nfs/turbo/coe-chaijy/janeding/regrounding/imagenet_val."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "import torchvision\n",
    "from vit_prisma.transforms import get_clip_val_transforms\n",
    "\n",
    "\n",
    "def load_imagenet(imagenet_validation_path):\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    # Load dataset with CLIP transform\n",
    "    data_transforms = get_clip_val_transforms()\n",
    "    val_data = torchvision.datasets.ImageFolder(\n",
    "        imagenet_validation_path, transform=data_transforms\n",
    "    )\n",
    "\n",
    "    # We'll also load a version of the dataset without the CLIP transform so that we can visualize it beautifully\n",
    "    viz_transforms = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    viz_data = torchvision.datasets.ImageFolder(\n",
    "        imagenet_validation_path, transform=viz_transforms\n",
    "    )\n",
    "\n",
    "    # We only want a subset of validation\n",
    "\n",
    "    subset_dataloader = DataLoader(\n",
    "        val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    # We only want a subset\n",
    "\n",
    "    return subset_dataloader, val_data, viz_data\n",
    "\n",
    "\n",
    "# Put your imagenet path here. You can download ImageNet from kaggle.\n",
    "imagenet_validation_path = (\n",
    "    \"/nfs/turbo/coe-chaijy/janeding/regrounding/imagenet_val\"\n",
    ")\n",
    "subset_dataloader, subset_dataset, viz_data = load_imagenet(\n",
    "    imagenet_validation_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accac5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prisma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
